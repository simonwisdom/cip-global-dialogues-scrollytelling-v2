"id","Response","Theme"
"5163","AI making medical diagnosis, as research has showed that AI is biased and it only makes a decision based on the algorithm and info fed to it before.If there is less information or research about a certain demographic of people or diseases, it doesn’t account it and it makes decisions technically and can’t be trusted with judging court cases as it cannot understand the complexities of human emotions and human spontaneity","Medical & Healthcare"
"5164","Helping me solve a very personal problem, I would not want to trust an AI with my deeply personal problems ","Personal & Emotional Life"
"5165","On how to educate children.

I think that being AI it would be based on theories of education and behavior, so it would be based on that information without caring about the feelings or considerations that a parent has for a child.

","Personal & Emotional Life"
"5166","AI making a decision in medical diagnosis and treatment for my loved one

eg.if my parent were diagnose with a complex illness I would hesitate to trust AI alone.While AI alone can analyse vast data and predict outcomes it lacks understanding of emotional context and empathy



","Medical & Healthcare"
"5167","It is Hard to make ai understandable. Sometimes I said some prompt, but I cannot understand it clearly or completely so they can like give really weird answer to me","General Mistrust / Inaccuracy"
"5168","decisions about the life and death of a human, the fact that an AI decides whether a child is born or not, or whether a person dies or not, even if it is for the greater good","Life-or-Death & Moral Dilemmas"
"5169","Communicating to AI on what I should do on my personal problems, for example in family. The AI would not know how I really feel and would not be able to emotionally connect to me even if I provide it with a lot of details.","Personal & Emotional Life"
"5170","To be diagnosed by an AI without a doctor present.  An AI does not know which symptoms can belong to more than 1 illness, and a doctor would know which relevant questions to ask to diagnose correctly","Medical & Healthcare"
"5171","For example where a family member is diagnosed with a serios illness and multiple treatment options arevavailable, each with its own risks, benefits and potential outcomes. An AI driven system offers recommendations based on medical data, past outcomes from similar cases and statistical analysis of success rates. Then the AI suggests one treatment plan as the best option based on its calculations. Why feel uncomfortable; because of emotional complexity, trust and accountability ","Medical & Healthcare"
"5172","Imagine an AI deciding judicial sentences based on data from past cases. I’d be uneasy because AI might miss the human nuances of each case, like individual circumstances and emotional context. The AI could also reinforce biases present in historical data, potentially leading to unfair sentences. Such decisions require empathy and moral judgment that AI might lack, making its recommendations less just and equitable than those made by a human judge.","Legal & Justice System"
"5173","Medical diagnosis. As machine learning tend to be flaw and it seem to have trouble with conflicting information, these require on-hand diagnosis and experience from real human. ","Medical & Healthcare"
"5174","In medical if AI is used and suppose if the decisions are made wrong , it may cause to dealth also.","Medical & Healthcare"
"5175","Let AI handle personal information, information about family members, and know in depth about my financial status.","Data Privacy & Security"
"5176","when AI are task to make ethical decision.  Not sure if AI are capable to doing so","Life-or-Death & Moral Dilemmas"
"5177","In legal matters, where an AI would analyze the case and say based on its knowledge whether the person is guilty or not. What makes me uncomfortable is not knowing clearly what led the AI to make a certain decision, what the factors were or even what theoretical basis it used.","Legal & Justice System"
"5178","Imagine an AI is being used to determine court verdicts on cases of various nature. I would prefer humans making the decisions since I believe there are situations where AI would not be able to comprehend e.g free will and paradox of choices in a human nature","Legal & Justice System"
"5179","Ai can't give information 100% valid must be control by human and can't develop it self must be developed by human","General Mistrust / Inaccuracy"
"5181","In health..AI may not be more good than humans in making health decisions","Medical & Healthcare"
"5182","If the AI is the court judge that will make me an easy for me to let it make a final decision ","Legal & Justice System"
"5183","AI making critical decisions about a person's health, reducing them to mere data without consideration of their emotional and psychological needs.","Medical & Healthcare"
"5184","When artificial intelligence chooses my treatment plan","Medical & Healthcare"
"5186","That the AI answers things for me without consulting or asking for anything first. I wouldn't like him to answer something without me having asked for it.","Loss of Human Agency & Control"
"5187","anything where I can overwrite the decision, I need to have the final say","Loss of Human Agency & Control"
"5188","AI can't make the decision that involved feelings. As such things i would not use AI to help me make a decision ","Personal & Emotional Life"
"5189","AI being used to make moral decisions especially during times of war and conflict.","Life-or-Death & Moral Dilemmas"
"5190","In court cases, an AI may be biased due to the data it has been trained on and discriminate against people based on their race, neurodivergence, etc.","Legal & Justice System"
"5191","AI making any decision related to my mental health","Medical & Healthcare"
"5192","I would not trust AI with decisions where the emotional background is key. I consider AI to be advisory at best, and not a tool that can make autonomous decisions. I need to be able to override it at any time.","Loss of Human Agency & Control"
"5193","AI making a decision instead of a jury","Legal & Justice System"
"5194","AI making diagnoses and modicum advice for people with mental illnesses ","Medical & Healthcare"
"5195","When AI sends messages without my intervention to the people I communicate with.","Loss of Human Agency & Control"
"5196","I wouldn't like to delegate tasks to an AI which require my personal touch like writing an eulogy, a birthday card, get well card or a letter to a loved one. I wouldn't think that an AI could recreate my personal style and even if it could, It wouldn't feel honest.","Creative & Artistic Pursuits"
"5197","I would feel uncomfortable with an AI making decisions in a legal trial, especially in determining someone's guilt or innocence. The complexity of human behavior, the need for empathy, and the nuances of morality are difficult for AI to fully grasp. The lack of transparency in how AI reaches its conclusions and the potential for biased data influencing outcomes make it uneasy to trust AI with such profound decisions that deeply impact lives and society.","Legal & Justice System"
"5198","In this scenario, there is a great deal of unease with AI making important decisions due to a combination of moral conundrums, algorithmic bias, accountability concerns, and the loss of human agency. While AI can improve safety and efficiency in many areas, human judgment is still indispensable in some sectors due to the complexity of human life and the subtleties of moral decision-making.","Life-or-Death & Moral Dilemmas"
"5199","in critical decisions that concern human life...because AI can also make mistakes and when these mistakes affect human life...it is serious","Life-or-Death & Moral Dilemmas"
"5200","A situation where AI has to decide on a case involving two people whose consequences may be fatal for both parties,since Ai have no feelings they can decide on something without heartfelt consideration.","Life-or-Death & Moral Dilemmas"
"5201","any decision that involves aspects related to morality and also to human emotions. It is difficult for a data set to allow AI to adapt to these contexts.","Personal & Emotional Life"
"5202","how AI can react and how other AI have more knowledge than human","General Mistrust / Inaccuracy"
"5203","In the criminal justice system, specifically in judicial decisions about a person's liberty, such as sentences in criminal cases or parole decisions.","Legal & Justice System"
"5204","In a scenario where an AI is tasked with making decisions in a medical context, I would feel uncomfortable it were to determine treatment plans for patients without human oversight. For example, if an AI analyzes patient data and decides to prioritize certain treatments based solely on statistical outcomes, it might overlook important nuances such as a patient's personal circumstances, emotional state, or unique medical history that a human doctor would consider.","Medical & Healthcare"
"5205","When AI makes decisions about our health and it wrongly interpretes, this could have dire consequences on humans and even affect our lives and wellbeing, including sweeping a lot of lives.","Medical & Healthcare"
"5206","I wouldn't AI examine my medical records for diagnosis of an illness. The lack of human empathy makes me skeptical of its learning ability to diagnose an illness very accurate. Also I would never let an AI systems write me a treatment for an illness. I am open to AI optimizing my treatment recommended by a medical expert but I will not subscribe to a treatment suggested by AI.","Medical & Healthcare"
"5207","I don't want AI interfere in personal decisons like family issues, relations, children using AI for everything as children should be kept away from AI for some years of there age for proper development

","Personal & Emotional Life"
"5208","In some scenarios, artificial intelligence will give dangerous instructions, such as Alexa.
Alexa once gave instructions to people to commit suicide.","Life-or-Death & Moral Dilemmas"
"5209","For Example that AI have the right to tell my Wive that she cant terminate pregnancy","Life-or-Death & Moral Dilemmas"
"5210","AI deciding on health care, it can be inaccurate and can lead to wrong decisions that can lead to overdose ","Medical & Healthcare"
"5212","When I ask a question over the phone, the operator is AI","General Mistrust / Inaccuracy"
"5213","Students using AI tools such as Chat GPT to help them write essays and do school work. I feel like that takes away from them getting an opportunity to use their brains and letting their creativity bloom. The use of such tools makes it so that they need to think out of the box. or let their imagination run wild. They won't know the basic rules of grammar or even know how to properly formulate sentences. ","Creative & Artistic Pursuits"
"5214","Solving court cases and determini g if someone is guilty or not","Legal & Justice System"
"5215","I systems that process sensitive medical data could be vulnerable to data breaches, leading to the unauthorized disclosure of personal health information.","Data Privacy & Security"
"5216","Judging a person based on their acute sudden action. when judging a person i can keep in mind about all the aspect regarding how the man usually behave with others, his potential and over all how he is as a human being, so some specific action cannot define a whole person in such short information or action. if ai takes decision, it will be taken totally based on the current information that is provided to the system only, not by knowing the man as how he is as a human being","Legal & Justice System"
"5217","I am concerned that the functions assigned to AI will not limit my freedom of choice.","Loss of Human Agency & Control"
"5218","I'm uneasy with AI making decisions concerning mental health ","Medical & Healthcare"
"5219","Any aspect of my life, from schedules to financial decisions. I think that even though an AI can quickly analyze large amounts of data, sometimes there are details that are only visible to humans, as we can better analyze the world around us and consider the emotional issues involved.","Financial Decisions"
"5220","the information provided may be false and inaccurate","General Mistrust / Inaccuracy"
"5221","Lack of contextual understanding. AI may fully not understand the nuances of human experience and qualifications ","General Mistrust / Inaccuracy"
"5222","ai may make a decision based on facts alone. whereas humans are more complex than that, humans have feelings.","Personal & Emotional Life"
"5223","when it comes to health issues, for sure i dont trust the AI decision reason being the machine has got no feelings hence it cant be true on health matters","Medical & Healthcare"
"5224","I would feel uneasy if an AI decided on legal sentencing or criminal justice matters, as it requires a deep understanding of context and empathy that might be lost in an automated process.","Legal & Justice System"
"5225","AI making decisions based on facts on basically anything without the input of emotions, empathy, personality etc  ","Personal & Emotional Life"
"5226","In deciding whether someone should live or not, I think AI could take into account the probability of someone living and not other factors. Unexpected miracles often happen.","Life-or-Death & Moral Dilemmas"
"5227","I would feel uncomfortable with AI making decisions in legal sentencing or parole cases because AI might lack empathy and struggle to grasp the complexities of human behavior. This could lead to decisions that don't fully consider the nuances of each individual case.","Legal & Justice System"
"5228","Medical decisions often involve psychological, social, and emotional aspects that AI may not fully understand. A human can take into account subtle factors and personal preferences that AI may overlook.","Medical & Healthcare"
"5229","I wouldn't ask AI to treat my health issues, because it is important to be analyzed with humans or doctors.","Medical & Healthcare"
"5230","Medical decisions, I would feel more comfortable talking with a doctor in person rather than a machine. ","Medical & Healthcare"
"5231","Deciding if a person is guilty in court and if they should be put to death","Legal & Justice System"
"5233","When it comes to making a medical decision, I prefer the judgment of a human being to that of any AI.","Medical & Healthcare"
"5234","In the medical field, doctors and trained medical professionals should make decisions, and not AI since the can be wrong. ","Medical & Healthcare"
"5235","That AI makes decisions about my work or family issues. I would be uncomfortable because AI would not take into account the personal and emotional part of the problem, but only the logical part.","Personal & Emotional Life"
"5236","When my child needs to apply for college, I need artificial intelligence to provide more detailed information so that we can make the final decision. Maybe artificial intelligence can understand children's preferences, interests and strengths, but I don't think artificial intelligence can really understand children's psychology, emotional changes and future demands. If we let artificial intelligence make the decision, we may regret it.","Personal & Emotional Life"
"5237","Regarding someone's health. Doctors can see and feel a patient's condition and assess accordingly. AI does not have such capabilities yet and will make textbook decisions. Even though it will be precise it won't understand the nuances of human behavior and processses","Medical & Healthcare"
"5238","One specific scenario is when AI makes an important decision for me, but mistakenly believes it fully understands my preferences and needs, and even misrecognizes my name in the process. The specific aspect that makes me uncomfortable is that AI not only fails to understand me correctly, but also tries to make judgments on interpersonal relationships or personalized needs on my behalf. This loss of control and personalized experience makes me feel disrespected and ignored.","Loss of Human Agency & Control"
"5239","As i believe AI will need lot of my personal data to understand my needs , may be making personal decision's and what i should be doing and eating these things this would make me extremely uncomfortable","Personal & Emotional Life"
"5241","Decisions about my medical treatment, my human rights or my government.","Medical & Healthcare"
"5242","AI, while capable of processing vast amounts of data, might struggle to understand the emotional and psychological impact of a diagnosis on a patient.Relying too heavily on AI could diminish the importance of human interaction and empathy in healthcare.

","Medical & Healthcare"
"5243","I feel uncomfortable to follow AI decision on something personal or involving values. For example, marriage timing or asking it to choose between 3 people I suggest. Also, about education as well because I still cannot trust everything AI said. Sometimes the information is not accurate at all. I also wouldn't rely AI to plan my schedule. I think it's become uncomfortable when it is a 'personal' thing. I don't want to feel like I am governed by AI when planning my daily life.","Personal & Emotional Life"
"5244","In health care. For example making a decision that would determine life or death of a patient. I want to a human to make the decision not AI","Medical & Healthcare"
"5247","In major criminal cases, AI systems decide whether to detain or release suspects. AI may not fully understand the emotional background and social environment of suspects, resulting in cold and mechanical decision-making. Or the AI decision-making process is not transparent, and its basis and reasoning cannot be effectively reviewed. If there is bias in the training data of the AI system, it may lead to unfair decisions and discrimination against certain groups. In particular, when the decision is wrong, it is difficult to determine who is responsible, which affects the fairness of the law and social trust.","Legal & Justice System"
"5248","Well for example I am asking suggestions for my health issues or other life issues and AI suddenly replies with my personal information or personal choices that I have never described to AI.","Data Privacy & Security"
"5249","when it comes to the nutrients i should eat to lose weight or gain muscle","Medical & Healthcare"
"5250","for instance when judging a person  in court","Legal & Justice System"
"5251","healthcare im more willing to trust a doctor with ""x"" years of experience an schooling expertise then newly trained ai system 

","Medical & Healthcare"
"5252","In medical diagnosis and treatment recommendations for a complex, life-threatening condition, such as cancer. AI lacks the human ability to understand the emotional and psychological aspects of a patient's experience.","Medical & Healthcare"
"5253","A religious decision. I am Christian. I have to follow the Bible. I feel AI would advise me to follow my will instead of God's will.","Personal & Emotional Life"
"5254","Health decisions. Health issues are critical and crucial topics and decisions that i will not let AI perform for me. For instance, when an AI is fed by data  concerning symptoms of particular disease and at the same time same symptoms are for another disease. As an AI can make judgements based on what it has been fed leaving the crucial facts on what disease someone is suffering from.","Medical & Healthcare"
"5255","The emotional part of a decision. Once, I was asking an AI about adopting a kid. its responses are very factual and without emotional addresses.","Personal & Emotional Life"
"5256","I would be afraid for my privacy and that the data the AI learns about me could be read by others or used against my will.","Data Privacy & Security"
"5257","Perhaps legal aspects, medical prescriptions (I would accept the diagnosis of an AI ONLY if it is reviewed by a doctor) and psychological or psychiatric issues.","Medical & Healthcare"
"5258","Decisions about signing documents","Financial Decisions"
"5259","He knows my personality, he knows what I think, he knows a lot about my private life and sensitive information that he can leak to anyone","Data Privacy & Security"
"5260","AI is not an emotional support, While working on a project the AI banned me from the project without knowing the reason and explanation.","Personal & Emotional Life"
"5262","a scenario that requires empathy the AI will make a logical decision which may lead to a disaster","Personal & Emotional Life"
"5263","Decisions that directly affect my rights and freedom: freedom of choice, movement, freedom of thought and the right to creativity.","Loss of Human Agency & Control"
"5264","AI may lack the emotional intelligence & moral reasoning needed to handle such sensitive & impactful choices effectively","Life-or-Death & Moral Dilemmas"
"5265","Imagine that AI completely takes over decision-making in the medical field, such as determining my treatment options and medication use. While AI may theoretically provide the most optimized treatment, it may make me feel uneasy if I find myself having no say in these decisions. Mainly because I cannot understand the AI's decision-making process, and this lack of transparency makes me feel uncomfortable.

In addition, medical decisions involve not only data, but also my personal feelings and quality of life. If AI makes decisions based solely on data, it may ignore my feelings about certain treatment options, such as the impact of side effects on my life. Such decisions seem cold and make me feel that I am being treated as a number rather than a person with unique needs and emotions.

In addition, if AI cannot fully understand my personal specific situation, such as living environment and special needs, this lack of personalization may make me feel that my situation has been reduced to a data point, which is difficult to accept.","Medical & Healthcare"
"5266","Medication administration, I would prefer that the person make their decision based on information provided by the doctor or AI.","Medical & Healthcare"
"5267","In the judicial sphere, I do not believe that AI can make decisions that require a degree of emotionality and understanding of the human condition.","Legal & Justice System"
"5268","AI making responses to a mail or message we got, which means it has access to our private messages and can reply accordingly. Which is an invasion of privacy, further more it will be used for more machine learning.","Data Privacy & Security"
"5269","Maybe a decision to show my most intimate health data","Data Privacy & Security"
"5270","If the AI choose for you your partner in life, your career, hobbies. Those are things individual have to decide for themselves. They can (and maybe should) consult the AI but the decision is theirs. ","Personal & Emotional Life"
"5271","medical decision.  The aspect of an AI prescribing a drug and making diagnosis.","Medical & Healthcare"
"5272","showing empathy. I feel AI cant really feel and show genuine emphaty like human. Another area is moral and ethical judgement. AI lacks moral and morality and probably wont understand culture and ethics and would have problem making decisions in areas like this","Personal & Emotional Life"
"5273","When it fails to answer a question ","General Mistrust / Inaccuracy"
"5274","I don’t think Al make decisions right as a human ","General Mistrust / Inaccuracy"
"5275","Like taking decision on family matter. Its a total relationship based decision .Algorithm can not take decision on humans emotion.","Personal & Emotional Life"
"5276","I would feel uncomfortable letting AI decide my financial decision because I do not know if that AI is controlled by some greedy entities","Financial Decisions"
"5277","I would think anything that has emotion attached. For example, I would not want AI to make a decision for me whether to stop breathing machine for my family members. I don’t want to regret over AI’s  decision.","Life-or-Death & Moral Dilemmas"
"5278","Given the autonomy to make decision too AI is too risky. There is too many certain aspect can't be considered thru AI decision making like morale and norm. ","Life-or-Death & Moral Dilemmas"
"5280","Health, probably. AI right now is not that accurate so I would probably not trust AI with my health or my family's.

","Medical & Healthcare"
"5281","The doctor's treatment diagnosis? My research direction, etc. Letting AI make the decision sounds very hasty and irresponsible","Medical & Healthcare"
"5282","I would feel uneasy with AI making medical decisions. While it can analyze data and suggest treatments, it might miss personal factors like my values or quality of life. For example, it could recommend aggressive treatment based only on stats. I’d prefer a human doctor to review and discuss the options with me, as medical decisions need human empathy and judgment.","Medical & Healthcare"
"5283","For example, in the hospital, when I questioned the decision of the AI, it would only give different answers but could not explain itself.","General Mistrust / Inaccuracy"
"5284","I would feel uncomfortable with an AI making a decision instead of a human is in judicial decisions. I would feel uneasy for several reasons:
Lake of contextual understanding, Biases in algorathem and data, lake of flexability.","Legal & Justice System"
"5285","When you're writing a research paper or anything new, AI will suggest a method that is same to everyone. I think that should be personalized.","Creative & Artistic Pursuits"
"5286","Imagine AI decides on a person's medical treatment, like which drugs or therapies to use. If the AI only considers data and ignores the patient's personal feelings and quality of life, I’d be uneasy. I’d worry that AI might miss the human side of care and make decisions that aren’t as compassionate or tailored to the individual","Medical & Healthcare"
"5287","I would feel uncomfortable to have AI as a teacher","Personal & Emotional Life"
"5288","For example deciding between 2 job offers. I feel AI would be unable to understand my personal connection to the companies durong my recruitment talks","Hiring & Employment Decisions"
"5289","Say there are two patients in the hospital and they both need a hear transplant but there is only one donor. Now AI could make an informed decision based on likelihood of recovery. While this might be the most rational option, I do not think AI playing God is morally acceptable,
","Life-or-Death & Moral Dilemmas"
"5290","I think that feelings cannot be used, it is unlikely that he will act according to our wishes.","Personal & Emotional Life"
"5291","When it comes to me, like my hobbies, my ideologies, decisions that make my personality emerge. If I let an AI do it, I would lose my personality and stop thinking about myself.","Personal & Emotional Life"
"5292","Decisions like what career i should take are decisions i wouldn't want AI to decide because it can't know my passions and what i feel towards a particular line of work ","Hiring & Employment Decisions"
"5293","prescription of medication, as an AI will not have as much knowledge and experience as a doctor who has seen several peculiar cases and would not be able to talk to the patient and explain and answer ever question the patient may have in regards to their issue","Medical & Healthcare"
"5295","If AI decides which person should I marry, or when will I get married ,or when should I start doing things. Like, it feels uncomfortable when AI is taking control over you and influences your decision making skills. ","Personal & Emotional Life"
"5296","When it comes to emotional judgments. Sometimes AI might be biased and might make wrong decisions. ","Personal & Emotional Life"
"5297","AI given decision making not suitable for business related and can't understand to read easily and it is higher level standard not simple ","Financial Decisions"
"5298","A scenario that would make me uncomfortable with Ai making a decision instead of a human is making a medical diagnosis for me.The aspect that make me uneasy are the fact Ai has to analyze my data,medical images and research to assist doctors in making accurate diagnosis and treatment plans.","Medical & Healthcare"
"5299","In a medical consultation, where the patient's data is entered into the AI system and without even looking at the patient, a complete diagnosis and treatment is provided","Medical & Healthcare"
"5300","1. If my disease is completely diagnosed by an intelligent system, I will be very worried. Artificial intelligence lacks experience and may not be 100% correct in complex situations. Over-reliance on artificial intelligence will also be a disaster. In addition, artificial intelligence lacks human emotions and empathy. Medical care is not just about data analysis, but also about emotional support, empathy, and psychological comfort for patients. Artificial intelligence may not be able to understand the emotional needs of patients, provide comfort, or communicate warmly with patients.","Medical & Healthcare"
"5301","in relatioship issues","Personal & Emotional Life"
"5302","So many decisions like taking an opinion","General Mistrust / Inaccuracy"
"5303","I think AI cannot take a decision on human relations. ","Personal & Emotional Life"
"5304","In life-and-death cases. Euthanasia cases. Death Penalty cases. In places where extreme emotion is involved and must be taken into account. AI will fail to accommodate for emotion.","Life-or-Death & Moral Dilemmas"
"5305","I would feel uncomfortable with AI when taking a decision which is totally based on emotion and one which can change my life completely I would rather trust on a human than AI for such decisions ","Personal & Emotional Life"
"5306","I would feel uncomfortable with AI making legal judgments in court cases. The lack of empathy, inability to consider nuanced human experiences, and potential bias in algorithms make it unsettling to entrust life-altering decisions to machines.","Legal & Justice System"
"5307","where AI make decisions on the type of prescriptive drug I will be given based on data about some disease symptoms it was fed with. It has control over my health..","Medical & Healthcare"
"5308","any aspects that involves human emotion like when it come to family matters as AI cant accurately predict human behavior. ","Personal & Emotional Life"
"5309","Example, AI making decision on which employee that should be fired from a company. Human should do the job.

What makes me uneasy, AI can not really 100% know about its maker condition, in this case is human.","Hiring & Employment Decisions"
"5310","Accident decisions in self-autonomous vehicles.

Explanation: If an autonomous vehicle is faced with an accident situation, the AI ​​has to decide which option to choose—should it let the vehicle crash into a wall, or take risks to avoid hitting pedestrians on the road. In such cases, the ethics of the decision are debated and the AI's ability to make ethical decisions may be limited.","Life-or-Death & Moral Dilemmas"
"5311","Email modification is very convenient, but I am worried about the leakage of personal information","Data Privacy & Security"
"5312","A scenario in which AI is tasked with deciding on criminal sentence including the duration of prison terms using data and predictive models. Aspects that may be uncomfortable include, equity and bias because the AI system may reinforce existing prejudices and result in unfair sentencing, thus justice may be undermined leading to incorrect findings against particular groups. AI may also not be able to fully understand every aspect of each case, such as the offender's past","Legal & Justice System"
"5313","If I need to make a decision on whether I should break up with my girlfriend, I would not let the AI make the decision for me because I don't believe AI can understand emotional values. ","Personal & Emotional Life"
"5314","I do not want AI deciding anything that would affect my continued life and happiness","Loss of Human Agency & Control"
"5315","For example, an AI asking me to share my bank details with it so that it can help me to manage my records and transactions better, but I wouldn’t be doing that as I feel it might leak this sensitive, personal information, which could pose a threat for me.","Data Privacy & Security"
"5317","What health decision to take","Medical & Healthcare"
"5318","It can be very dangerous because all decisions would be with no emotion. I could feel so uncomfortable. I could use Ai just for having an info about math problems or some basic stuff. ","Personal & Emotional Life"
"5319","For example, if an AI virtual assistant were to evaluate me for a job, only considering the information I provide in a CV, without considering my presentation as a person and how I conduct myself (as is done in an interview between people).","Hiring & Employment Decisions"
"5320","I think AI does not have real emotions, so it can't feel the problem and make a good decision.","Personal & Emotional Life"
"5321","For example, if I take my children to the park to play, I would feel uncomfortable if artificial intelligence made a decision for me, because AI's decision is only the result of data analysis. There are no emotional factors involved, which will affect the results we really want.","Personal & Emotional Life"
"5322","On emotional things which ai couldn't respond the way human does","Personal & Emotional Life"
"5323","In a medical context I wouldn't be comfortable letting AI make the decision.","Medical & Healthcare"
"5324","A scenario of clinical diagnosis in a patient symptom.. Aspects of diagnosis include a great rapport,good history taking and proper examination.using AI as an alternative to health care workers is dangerous since the aspects of rapport with the patient more so from third world countries that don't understand English will be difficult.then the examination part will also not be present.This makes it very uneasy for me","Medical & Healthcare"
"5325","any instance where human judgment is needed. AI have no human emotions to know right from wrong under different circumstances.","Personal & Emotional Life"
"5326","I don't think AI giving medical advices are necessarily a good thing . It's the matter of a human life. I feel like a real person's opinion and assesment is needed to make medical decisions. I am not very comfortable with that idea.","Medical & Healthcare"
"5329","I did feel uncomfortable with AI making medical  treatment decisions. The specific aspects that make me uneasy include:  1. AI  might not fully understand the emotional and psychological aspects of patient care.

2. AI might miss nuanced, personal factors that a human doctor would consider in treatment decisions. 

3. If something goes wrong, it is clear who would be held accountable, potentially leading to a lack of recourse for patients.







","Medical & Healthcare"
"5330","In decision making human are much better Ai . Because the emotions we feel Ai would never make decisions on emotional basis for example.

AI making a decision in hospital for patients and what food to give them without seeing a patient emotionally and where they belong to makes me uneasy.It should be a human task ","Medical & Healthcare"
"5331","When it comes to an AI making decisions on my daily lifestyles like on what I should eat, I'm uncomfortable with that because it can't know my desires","Personal & Emotional Life"
"5332","Asking AI about my symptoms instead of visiting the hospital for consultations and diagnosis.","Medical & Healthcare"
"5333","How to best raise my child.","Personal & Emotional Life"
"5334","when it will ask a lot of personal information like disclosing of personal assest","Data Privacy & Security"
"5335","Some personal questions or scenario related to family issues or health concerned","Personal & Emotional Life"
"5336","Judging suspects for crimes.

Making medical decisions on behalf of a person.

In the above two scenarios, AI is first and foremost a machine, and above there needs to be a human touch that can recognize emotions and motives","Legal & Justice System"
"5337","An AI making a decision on my health will feel uneasy because I'm not quite sure of how an AI will delegate my health condition.","Medical & Healthcare"
"5338","B is better, AI just a tool that can help us make the decision. It is not the one direct make decision for us.","Loss of Human Agency & Control"
"5339","Imagine a scenario where an AI system, without human oversight, diagnoses a serious illness. I might feel uncomfortable due to the lack of human empathy, the potential for errors, and the loss of control over my own healthcare. While AI can be a valuable tool in medical diagnosis, human input is crucial to ensure that the AI's recommendations are in the best interest of the patient. A human doctor can provide context and address concerns.","Medical & Healthcare"
"5340","AI can affect the income of one's person","Financial Decisions"
"5341","For example, a decision about what to do naturally at home for an illness can be dangerous. One cannot know whether the person has an allergy or not.","Medical & Healthcare"
"5342","Writing a message to a loved one, because it influences feelings and is also not sincere. Making the decision about my health","Personal & Emotional Life"
"5343","I would be uncomfortable with the fact that they make a decision that seems right to the AI, but for me, the fact that they lack empathy can give them a certain advantage when it comes to optimizing resources, an aspect that does not apply to humans.","Personal & Emotional Life"
"5344","When the AI system is unable to differentiate between my personal private time and working time.","Loss of Human Agency & Control"
"5347","If we are talking about AI having exclusively cognitive abilities, and everything connected with emotions and soul is alien to it, then I would not be able to delegate any moral dilemmas or ethical issues to AI. Since in this case AI will be guided exclusively by dry data, and still sometimes emotional manifestation and empathy are needed.","Life-or-Death & Moral Dilemmas"
"5348","The confident answers to each query makes me uneasy. While using AI what I have observed is, many times AI gives wrong answers but it gives it so confidently that I would believe in it. Also many times it gives repeated answers.","General Mistrust / Inaccuracy"
"5349","As AI does not have feelings ","Personal & Emotional Life"
"5350","I would be uncomfortable with AI making major medical decisions.","Medical & Healthcare"
"5351","In healthcare, I would not want to purely rely on an AI system to listen to my symptoms, come up with a diagnosis, and prescribe the medicine. I would want to have a human being involved in that process.","Medical & Healthcare"
"5352","For example, when I decide what electronic product to buy, I don’t trust the push of big data. I would rather do my own research so that I can feel at ease.","Loss of Human Agency & Control"
"5353","Its about privacy as a woman i don't feel safe because ai make photos himself and its also dangerous ","Data Privacy & Security"
"5354","For example, the selection of candidates for a job, where AI participates in decision making, taking into account skills, merits and awards, experience and age, but not taking into account human qualities such as diligence, emotionality, integrity, honesty, emotional type of a Person.","Hiring & Employment Decisions"
"5355","As of now to AI is still not there for example, Take a picture of a school bus. Flip it so it lays on its side, as it might be found in the case of an accident in the real world. A 2018 study found that state-of-the-art AIs that would normally correctly identify the school bus right-side-up failed to do so on average 97 percent of the time when it was rotated.","General Mistrust / Inaccuracy"
"5356","Evaluating an answer script...","Creative & Artistic Pursuits"
"5357","When it comes to not typical problems and ethical dilemmas. It’s uncomfortable when AI calculates outcomes instead of compassion","Life-or-Death & Moral Dilemmas"
"5358","If AI is making decision about my emotional state I would not be very happy or comfortable as AI cannot determine my emotional state even if I say I am happy or sad. ","Personal & Emotional Life"
"5359","lack of human knowledge and also AI cant have feeling to consider about human life struggles ","Personal & Emotional Life"
"5360","I'd be uncomfortable even if AI is simply used for determining if something in a text is factual. There are already cases where AI would completely say untrue things confidently and expertly.","General Mistrust / Inaccuracy"
"5361","Making massive life changing decisions, like things regarding life-changing medical decisions. It feels terrifying that I'm letting an AI make such an important decision for me, like I'm being stripped of my autonomy","Medical & Healthcare"
"5362","AI makes data analysis faster and more accurate. It helps in making better decisions by identifying patterns and trends in large data sets. The use of AI saves both time and effort.","Uncategorized"
"5363","That he makes decisions about what to write on my behalf in my personal relationships, that he gets involved in my personal relationships in general. Like answering wwsp or instagram on my behalf, because it's not what I feel.","Personal & Emotional Life"
"5364","Decisions regarding personal freedom, such as where to live, what to eat, what activities to do in my free time, all of which I have no right to voice or vote on in these decisions.","Loss of Human Agency & Control"
"5365","specific aspects causing uneasiness","Uncategorized"
"5366","My privacy may be known by others
","Data Privacy & Security"
"5367","If I encounter an emotional problem, I would not want AI to participate in making decisions, because emotional problems are very complicated, and we cannot predict what is happening or will happen in the future based on what happened before. Every emotional conflict, its cause and subsequent development are unpredictable, and people need to make appropriate responses based on the situation and communication at the time. It would be very unreasonable to simply rely on AI to deal with it in a rough and crude way based on previous examples.","Personal & Emotional Life"
"5368","I’d feel uneasy about an AI making decisions on legal sentencing because it might lack the nuanced understanding of individual circumstances, ethical considerations, and empathy needed for fair and just outcomes. Additionally, AI may perpetuate biases and complicate accountability.","Legal & Justice System"
"5369","That 'BIG DATA' has bunch of privacy information, making order with text is make that bigger.","Data Privacy & Security"
"5370","When it will ask my personal information like bank details, family, and helath issues.","Data Privacy & Security"
"5371","I would feel uncomfortable with an AI making a decision in a medical enviroment because I beleive a human doctor should be the only one making decisions for patients and diagnosing them.","Medical & Healthcare"
"5372","many private information and decision that humans do should still retain to human like getting married, settling a dispute","Personal & Emotional Life"
"5373","AI suggests me wrong recommendations that don't suit to my lifestyle.","General Mistrust / Inaccuracy"
"5374","AI to decide on my daily routine ","Personal & Emotional Life"
"5375","I would hesitate to give AI the right to take any life altering decision for me. Take career for example. The choices open to me are know to me and even tho AI can give me a detailed version yet I don't trust it completely. I might ask for advice as it's knowledge is incomparable but I won't just agree with it's decision. ","Hiring & Employment Decisions"
"5376","When AI decide for me fully without respecting my opinion ","Loss of Human Agency & Control"
"5377","Any decision that involves human suffering, taking someone's life, that could harm someone's health or financial stability, that is not just operational, repeating tasks. Any serious decision by an AI needs human approval.","Life-or-Death & Moral Dilemmas"
"5378","If I need to make a decision of if I should break up with my girlfriend, I would not trust AI to make that decision. Because AI do not have emotion, and they have not been in an relationship. ","Personal & Emotional Life"
"5379","Asking AI to help in relationships and sharing person data as it could be gathered by companies","Personal & Emotional Life"
"5380","the decision of whether the person should be fired or not","Hiring & Employment Decisions"
"5381","Everything that concerns private life.","Personal & Emotional Life"
"5382","in topics where a sensitive side is required, or more focused on the social, mental consequences of a person","Personal & Emotional Life"
"5383","If i need to get solution for my personal problem like pcos or pcod. If i get a solution from an AI, I would be uneasy as a human need to decide and give any treatment for it","Medical & Healthcare"
"5384","Serious health decisions with out human input
","Medical & Healthcare"
"5385","In criminal justice, cops have already begun using AI to recognize faces from CCTV footage. I would not feel comfortable leaving decisions of who a suspect might be to an AI, because the AI might have a false positive or malfunction and choose the wrong person, thus leading to an unfair sentence.","Legal & Justice System"
"5386","Mmm actually I think that in almost all situations, understanding that AI MAKES the decision, I do not agree with that, AI should always SUGGEST, and we make the final decision","Loss of Human Agency & Control"
"5388","like for example giving orders for meds for sick people","Medical & Healthcare"
"5389","For example writing a CV.","Hiring & Employment Decisions"
"5390","In more emotional situations that impartial point of view of an AI is not necessary","Personal & Emotional Life"
"5391","At first I'm less likely to trust artificial intelligence to make health decisions for me, I'd rather have a human do it
","Medical & Healthcare"
"5392","Writing news text or social media content","Creative & Artistic Pursuits"
"5393","I would be disappointed if an AI chatted with me when I needed emotional support
","Personal & Emotional Life"
"5394","May be a doctor where AI can prescribe some personal medication or something related to issues of pregnancy and health decisions. ","Medical & Healthcare"
"5395","AI regulations, how humans should behave towards each other, life and death","Life-or-Death & Moral Dilemmas"
"5396","I would not want AI making decisions for me such as monetary transactions as that is something that is quite personal for me and I feel will be interfering with my personal space and decision making.","Financial Decisions"
"5399","AI in healthcare, especially if AI is used to make decisions concerning serious medical conditions","Medical & Healthcare"
"5400","In the medical field, I recognize that AI is going to help medicine a lot, but that a diagnosis on its own is quite risky, since it depends on the patient's data that it has. If a person who ignores symptoms or other data from their medical history asks for advice, the AI's response may be far from being the remedy or therapy that they need.","Medical & Healthcare"
"5401","Taking legal action and being advised by an AI does not seem to me to be the most correct and pleasant thing to do. There are behaviors and conducts that cannot be replicated.","Legal & Justice System"
"5402","A AI making decisions about my health instead of a doctor would make me feel very anxious and uncomfortable. I can only trust a doctor and might feel like AI is preprogrammed and won't be helpful and accurate in every decision ","Medical & Healthcare"
"5403","I’d feel uncomfortable with AI making decisions in a legal trial, particularly in determining guilt or sentencing. Even with vast data, legal cases often involve nuanced human emotions, ethical judgments, and societal context that AI might struggle to fully grasp. The thought of an AI lacking empathy and the ability to consider the broader moral implications of a person’s actions makes me uneasy. I would worry about the AI reducing complex human experiences to patterns and probabilities, potenti","Legal & Justice System"
"5404","It would be uncomfortable if AI provided life advice that did not align with my personal values, preferences, or religion.","Personal & Emotional Life"
"5405","An AI making any decision that impacts human life - whether it be a business investment or mental health diagnosis. There is no way to know how much the AI's corporate master has influenced the decision ","Medical & Healthcare"
"5406","Lack of creativity and passion in decisions","Creative & Artistic Pursuits"
"5407","AI might not handle new or unusual situations that a man used to do. sometimes it makes some unclear decisions making it hard to trust or question them. AI may not understand the feelings of the situation like a person.","General Mistrust / Inaccuracy"
"5408","When it comes to personal health or financial decisions, I would feel uncomfortable if artificial intelligence made decisions for me. Artificial intelligence can provide me with data references, but it cannot make decisions for me. The final decision needs to be made by me based on my own habits and personal preferences.","Medical & Healthcare"
"5409","A concrete scenario where I would feel uncomfortable with AI making decisions instead of a human is in criminal justice sentencing. Imagine a courtroom where, after the trial, an AI algorithm is tasked with determining the length of a prison sentence based on data like past cases, criminal records, and behavioral predictions.","Legal & Justice System"
"5410","A scenario where i would feel uncomfortable with an AI making decision on my behalf would be my personal decisions like my feelings. I’d feel uneasy using AI for decisions about personal privacy, such as choosing who should be watched or investigated based on their data. What bothers me is the chance of biased algorithms, not knowing how decisions are made, and the risk of invading personal privacy without proper human oversight or consent & makes individual privacy levulnerable to uncomfortable","Data Privacy & Security"
"5411","Relationship management is something where i dont want AI to play a big role....","Personal & Emotional Life"
"5412","Involving emotions. For example, if AI decides whether my parents, lover, or children should meet me, I will feel very uncomfortable because I think AI cannot replace the real emotions of my loved ones.","Personal & Emotional Life"
"5413","I'd be uneasy with AI deciding child custody in divorces. The complexity of family dynamics, emotional needs, and a child's best interests requires human empathy and judgment. An AI might miss subtle emotional cues or unique family circumstances. There's also the risk of bias from historical data. The stakes are too high - a child's wellbeing and family relationships - to rely solely on algorithmic decision-making, even if it could process more case data than a human judge.","Legal & Justice System"
"5415","Ethical and Moral decisions should be taken by human beings, not AI.","Life-or-Death & Moral Dilemmas"
"5416","I believe AI lacks the emotions and empathy that humans have. AI only has the tendency to think logically and that is not the best decision in every scenario.

If there is a deadline to a school project and the responses are to be submitted an review by AI. If a specific student is struggling with academics or recently faced an emergency due to which the kid couldn't submit the project on time or it was made in a rush then AI cannot understand and empathize in such cases. But a human teacher can","Personal & Emotional Life"
"5417","If I am unhappy at work and decide whether to quit, I guess AI will say no. It does not understand human emotions and is too rational. It will only give the so-called standard answer, which will be annoying.","Hiring & Employment Decisions"
"5418","It makes decisions for people regarding their wealth management, health management, and personal career direction. I think it is more suitable to be an assistant rather than a tool that plays a decisive role.","Financial Decisions"
"5419","Questions involving human intellectual thinking","Creative & Artistic Pursuits"
"5420","A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human is in the context of criminal justice, specifically in sentencing decisions for criminal cases. AI systems could analyze vast amounts of data to recommend sentences based on historical trends, but this could lead to serious issues like bias reinforcement and lack of empathy.

What makes me uneasy in this scenario is that AI might perpetuate or even exacerbate existing biases present in historical","Legal & Justice System"
"5421","relationships related decisions","Personal & Emotional Life"
"5422","Artificial intelligence cannot make emotional decisions for me, such as communicating with friends, handing over work, etc.","Personal & Emotional Life"
"5423","About trivial decisions like what to wear, what to eat, what activities to do, who to socialize with, self-imposed beliefs, woke culture","Personal & Emotional Life"
"5424","I would feel uncomfortable with an AI making decisions about hiring or firing employees. In such scenarios, the human element is crucial for understanding nuances like interpersonal dynamics, potential, and context that AI might miss. Decisions that affect people's careers and livelihoods require empathy, understanding, and ethical considerations that go beyond data and algorithms. The risk of AI lacking the emotional intelligence to handle such sensitive matters could lead to decisions that are","Hiring & Employment Decisions"
"5425","personal information","Data Privacy & Security"
"5426","Private life","Personal & Emotional Life"
"5427","Anything related with emotions. Like which food i will eat. It depends on my mood.","Personal & Emotional Life"
"5428","If an AI prevented someone from professing a faith.","Personal & Emotional Life"
"5429","Making life-altering decisions, like where to go to school or what career should I pursue.","Personal & Emotional Life"
"5430","Avoid Taking decisions made by the AI.","Loss of Human Agency & Control"
"5431","I would feel uncomfortable with an AI making decisions about my health. I wouldn't trust that it could take everything into account and organise treatments that may be inappropriate.","Medical & Healthcare"
"5432","Obviously, in terms of health. I honestly wouldn't like artificial intelligence, at least today, to decide what kind of treatment I should follow, much less if this treatment is based only on symptoms and not on medical check-ups.","Medical & Healthcare"
"5433","Being told how to do my job, for example, I think would make me feel a little bit useless in that sense, like I wasn't necessary for my job.","Hiring & Employment Decisions"
"5434","Medical decisions, for me, even if I describe the symptoms to artificial intelligence, I do not think that we have reached a high level of development to rely on artificial intelligence decisions.","Medical & Healthcare"
"5435","In scenarios involving big decisions like picking a medicine. That should be done by a professional. ","Medical & Healthcare"
"5436","Personal and social life.its an aspect of personal emotions, or aspect of belonging ","Personal & Emotional Life"
"5437","Lack of feelings or humanity in decision making, which makes decisions and outcomes a purely logical process without considering feelings or other people, such as the decision to start a war.","Life-or-Death & Moral Dilemmas"
"5438","AI reading resumes and doing the initial screening makes me uneasy. People spend hours perfecting their resume. It should not be given a cursory glance by an AI, not even a human, and tossed in the bin if certain keywords don't match. Maybe keywords aren't there but they have the relevant experience. A human must and should screen resumes.","Hiring & Employment Decisions"
"5439","The survey findings indicate that people are feeling disempowered by lost control over their digital footprint, and by corporations and government agencies adopting AI technology to make life-altering decisions about them","Loss of Human Agency & Control"
"5440","Placing it in control of my finances. Hypothetically an AI model could make considerably better decisions on the stock market than a human could because of the potential for it to perform advanced analysis of trends. Acknowledging this, I still would not delegate control over my finances to an AI because I prefer to feel in control of my own decisions, especially when it's something important such as money","Financial Decisions"
"5441","Concrete scenario where I would feel uncomfortable with an AI making decision instead of a human is Ai making decision at the time of war","Life-or-Death & Moral Dilemmas"
"5442","AI in any crucial decision position is a lost case. Ai has biases, it might be trained and refined and tested and refined again, but some biases might be hidden. A study of AI classifying Resumes for a job has shown that it was kind of racist in the classification, labeling Asians and whites at the top and Africans at the bottom. Would you really let AI make decisions in crucial cases if you knew that? I won't, we think by using AI we are overcoming human error, but we're falling into AI biases.","Hiring & Employment Decisions"
"5443","A scenario where one has a chronic illness and AI has to decide on the issue of life support.","Life-or-Death & Moral Dilemmas"
"5444","Translate text. The current capabilities of artificial intelligence are not yet capable of handling difficult translation tasks, and various errors may occur in the translation.","General Mistrust / Inaccuracy"
"5445","The main scenario would be giving complete authorization to make payments using AI. AI is supposed to mimic human behavior, and humans tend to have emotional constraints which could show in advanced AIs after a few years, making them think independently and plot a course of actions which could be harmful to humans.","Financial Decisions"
"5446","things about feeling ","Personal & Emotional Life"
"5447","I would feel uncomfortable if an AI decided for me on judicial matters, without knowing the context or the value that humans give to certain things that can influence our actions.","Legal & Justice System"
"5448","Deciding, for example, not to take action on something. If someone has a problem, present a standard solution applicable only to the text or chat space without implying that AI is not a way of life but a tool for life and that another human should be consulted for making health decisions, for example.","Medical & Healthcare"
"5449","I would be uneasy about AI making decisions involving complex ethical or moral considerations, such as issues related to justice, human rights, or end-of-life care.","Life-or-Death & Moral Dilemmas"
"5450","I would feel uncomfortable with an AI making any important medical decisions including diagnoses and treatment plans as I would trust a trained human over Ai in its current form. ","Medical & Healthcare"
"5451","deciding if someone is guilty of a crime and their punishment. I'm worried about biases in data, lack of empathy, the lack of ability to backtrack the decision, and the lack of accountability in the case of an error","Legal & Justice System"
"5452","I would be uncomfortable if AI decided issues related to ethical choices","Life-or-Death & Moral Dilemmas"
"5453","AI may make an efficient recommendation for a task but miss the human preferences or subjective values that should be considered.","Personal & Emotional Life"
"5454","I would be very uncomfortable if AI were to take the place of a lawyer and make decisions. The idea of AI completely going ""by the book"" and not understanding or trying to listen to the person is concerning.","Legal & Justice System"
"5455","Health and security issues. AI may decide to delay your treatment in favor of someone else just because it is efficient. As for security, AI may lead to elimination or arrest of people deemed dangerous before they even have a chance to prove otherwise ","Medical & Healthcare"
"5456","A concrete scenario where someone might feel uncomfortable with AI decision-making is in hiring for jobs. If an AI selects candidates based on algorithms, people may worry that it could make biased or unfair decisions, overlooking qualified individuals due to factors like past data patterns or hidden biases in the system. This lack of transparency can make people feel uneasy about trusting the AI's judgment.","Hiring & Employment Decisions"
"5457","I think I would feel uncomfortable on vacations and finance aspects. What happens if I do not like the decisions made by AI on my vacation. This will ruin my vacation. I am scared that AI may make mistakes in my finance and investments and leading me to become poor.","Financial Decisions"
"5458","I would feel uncomfortable if an AI made a decision about my medical treatment during a complex, life-threatening condition. For example, if an AI algorithm recommended a treatment plan based solely on statistical data, without considering my personal values or discussing the risks and trade-offs with me, I'd be uneasy. The lack of human empathy, emotional understanding, and the inability to weigh my preferences in context would make me distrustful of such decisions. ","Medical & Healthcare"
"5459","AI control over my finances, my work life, my home devices, my access to accurate information (since AI has quite the reputation for providing factually incorrect information as if it is correct, while search engines are prioritising AI responses over human-written articles), my access to medical information, and much more","Loss of Human Agency & Control"
"5460","In a medical scenario where I have to undergo a risky procedure. I would feel uneasy with AI making the decision because AI lacks empathy. A humans decision will give me more confidence and put me at ease","Medical & Healthcare"
"5461","AI is implanted in my brain to monitor my everyday life and this data is being collected to one day control me. The fact that someone is spying on my life and collecting data to one day restrain me makes me very uneasy","Data Privacy & Security"
"5462","If AI were to make decisions on delicate personal problems, including sophisticated emotional support or end-of-life care, I would find it unpleasant. The human quality of empathy, comprehension, and moral judgment is essential in these kinds of situations. Even with its data-driven powers, AI might not have the ethical awareness and complex emotional intelligence needed in these circumstances. ","Personal & Emotional Life"
"5463","I would feel uncomfortable with AI making legal decisions, like sentencing in court cases. AI might lack the ability to understand human intent, emotions, and moral complexity, and there’s a risk of bias based on the data it’s trained on. The absence of empathy and ethical judgment in such decisions makes me uneasy.","Legal & Justice System"
"5464","I worry about AI makes a bad decision and I did not know it.","General Mistrust / Inaccuracy"
"5465","An AI system is used in a criminal justice system to determine sentencing recommendations for offenders. The AI analyzes data such as the offender’s criminal history, social background, and case details to suggest sentences.","Legal & Justice System"
"5467","What health program I should take for my symptoms. Decisions on my eligibility doing something in the major life events. Am I a good citizen.","Medical & Healthcare"
"5468","Off the top of my head, abortion. AI would never know a single thing about having a child or what it would feel like to terminate one or the decisions and emotions that would lead someone to require the procedure","Life-or-Death & Moral Dilemmas"
"5469","In a health situation, I would trust a doctor more than AI.","Medical & Healthcare"
"5470","any decision about life and death. Someone who gets sentenced to death by AI. That would make me really uncomfortable to even  think about. 
","Life-or-Death & Moral Dilemmas"
"5471","Full control over the humans, should be advisor,an assistant to help in their regular life, should not take over them.","Loss of Human Agency & Control"
"5472","In life or death situations where there are two people in danger, and only one can be saved. AI being the deciding factor on who to save is what makes me feel uneasy, as it is something you should not simply base on numbers and data that has been fed into a machine, but something based on human feelings and emotions in the moment.","Life-or-Death & Moral Dilemmas"
"5473","i would feel uncomfortable if AI makes a decision on the path that a vehicle is to take while moving along a busy road. this is because it may cause unnecessary accidents in case of failure leading to deaths","Life-or-Death & Moral Dilemmas"
"5474","I think if AI made decisions that I might not agree with, but I would have to do as the AI's command, that is, a complete lack of freedom of choice. I need a consultant, not a manager of my entire life.","Loss of Human Agency & Control"
"5475","Anything involving health decisions. I think it is great to provide data about my health but I think the ultimate decision should be up to me and my doctor","Medical & Healthcare"
"5476","absence of emotions","Personal & Emotional Life"
"5477","AI would need some time to learn about my life style or decision making style. Before they adapt to me, there will be some errors.","General Mistrust / Inaccuracy"
"5478","Payments and my personal finances. I don't trust AI to take control of my finances. I would still be on doubt and would need to check if it paid my bill even if it said it did. Or it can accidentally use and pay for something Or, let's say the financial investment ideas an AI would give. Things like this would are too risky with AI. ","Financial Decisions"
"5479","Decisions such as securing a particular facility using AI, where the AI decides to shoot the wrong person.","Life-or-Death & Moral Dilemmas"
"5481","Comforting my friend whom just break up from her boyfriend, or deciding if to cut off the machines if a family member is brain dead.","Personal & Emotional Life"
"5482","REPLACE MY THINKING PROSES, MY ABILITY TO SOLVE THINGS","Loss of Human Agency & Control"
"5483","Emotional decisions and financial decisions are something where we can't rely on AI. So these place I would feel uneasy and will definitely need human intervention to clear my doubts.","Personal & Emotional Life"
"5484","I would feel uncomfortable with AI making decisions about sensitive personal matters, such as choosing a long-term partner or making medical decisions. In these scenarios, the nuances of human emotions, values, and personal experiences are critical and might be overlooked by AI. The lack of empathy, understanding of complex human dynamics, and the potential for misinterpreting personal context make me uneasy, as these decisions profoundly impact well-being and life satisfaction.","Personal & Emotional Life"
"5485","Not really sure, I think around relationship advice. At this stage I think AI does not have enough personal knowledge and could give bad or general instructions that do not suit your or aprthers personality.

","Personal & Emotional Life"
"5486","Incase of disciplinary actions cases","Legal & Justice System"
"5487","AI shouldn’t be used in tasks such as law-making and courts, as it may not take into consideration human factors and believe every situation to be clear cut, which is not always the case. ","Legal & Justice System"
"5488","When AI decides how i should raise my children or give me inaccurate information of medicines that I should use.","Personal & Emotional Life"
"5489","The aspects of emotion, it would make me uneasy if AI makes a decision as AI has no emotion.","Personal & Emotional Life"
"5490","I would not allow AI to speak for me.
I expect subtleties won't be understood.","Loss of Human Agency & Control"
"5491","Imagine an AI tasked with determining a cancer treatment plan based on detailed data, such as genetic information and medical history. This situation raises several concerns: First, AI lacks the empathy and emotional support that human doctors can offer, which is vital during such a challenging time. Second, AI might struggle with the complex ethical and personal values involved in treatment decisions. Third, determining accountability for any negative outcomes is unclear when AI is involved. ","Medical & Healthcare"
"5492","Involving AI in family affairs ","Personal & Emotional Life"
"5493","Artificial intelligence determines my treatment plan. I don't fully trust artificial intelligence, and I don't want to disclose my health privacy.","Medical & Healthcare"
"5494","If a pregnant woman is in danger during childbirth, the doctor asks whether to save the child or the mother. If AI decides that the right thing to do is to save the child because the mother's chances of survival are slim, then even if I follow its correct decision, I will find it difficult to accept emotionally.","Life-or-Death & Moral Dilemmas"
"5495","career decisions. I think it would take away the ability for one to choose. let's say AI is designing a personalized job, however, unlike AI we change once in a while and the way we change is different than how AI changes. While AI becomes more efficient, we as people change our priorities and AI might not always comprehend our priorities","Hiring & Employment Decisions"
"5496","If AI controls my life, I will feel uncomfortable. I should be in complete control of my life and make my own decisions.","Loss of Human Agency & Control"
"5497","My eating and lifestyle habits, I may refrain from AI.","Personal & Emotional Life"
"5498","the most emotional and extreme decisions such as the decision to save one life over another","Life-or-Death & Moral Dilemmas"
"5499","Resigning from my job that I love so much.","Hiring & Employment Decisions"
"5500","if I was in an HR department in a company, I would feel uncomfortable using AI to choose the best candidate for a job vacancy, because AI might have biases from the data it collected, it might lead to favoring some ethnic group or gender over another","Hiring & Employment Decisions"
"5501","You may also have concerns about privacy, security, and the ethical use of AI. The idea of losing control to machines or facing decisions made by algorithms without empathy can be daunting.","Data Privacy & Security"
"5502","more emotional aspects For example, it can be a psychologist","Personal & Emotional Life"
"5503","all decisions related to ethical choice","Life-or-Death & Moral Dilemmas"
"5504","I would be uncomfortable with AI making a decision about any health issues. The gut feel feeling of a real doctor would be missing in AI making decisions about health issues.","Medical & Healthcare"
"5505","What happened to my husband or other loved ones. It would make me uneasy because in the case my husband was sick I want to make those choices. I would make them out of love not an algorithm.","Medical & Healthcare"
"5506","Automatically rephrasing what I write makes me feel uncomfortable because I'm the one who has to set the tone.","Loss of Human Agency & Control"
"5507","An AI making decisions that will greatly affect human life makes me uncomfortable. An example I can think of is when an AI gets to decide over a person's life in medical care. Compiled data and predictions are helpful in understanding a medical situation but ultimately, the doctor and the a patient should talk and decide, as factoring in human emotions are important in these situations.","Medical & Healthcare"
"5508","Sometimes you have taken the decision from heart even if results in your loss but ai will always take the decision based on profit ","Personal & Emotional Life"
"5509","I can't trust AI giving me advice about my health or giving investment advices","Medical & Healthcare"
"5510","I would be uncomfortable with AI making decisions that have to do with my interpersonal relationships. These types of decisions have to do with our feelings and emotions, and I believe that AI, no matter how much information it has, is not capable of making decisions in that field.","Personal & Emotional Life"
"5511","Deciding or not whether to put a pet to sleep (euthanasia). This is mostly an emotional situation that can cause a lot of distress to the individual.","Life-or-Death & Moral Dilemmas"
"5512","Taking financial advice or discussing my health with the AI.","Financial Decisions"
"5513","Situations involving my health. Just like any other computer AI can fail. ","Medical & Healthcare"
"5514","I don't think AI should be making decisions for human. AI can help provide the options but ultimately, the choice should be down to the human. For a concrete example, it would make me extremely uncomfortable in healthcare scenarios. When I would need to consult with an AI instead of an actual human doctor.","Medical & Healthcare"
"5515","I would say possibly any related to health. There are human beings and emotions involved. For instance, say somebody is on the ventilator and you need to make the decision about pulling the plug. AI will only predict from a logical point of view and will not take into account the power of the human spirit and the power of hope and manifestation!","Medical & Healthcare"
"5516","Just because artificial intelligence makes a decision doesn’t mean I have to follow it. Its decision is only for reference, so I won’t feel uncomfortable.","Loss of Human Agency & Control"
"5517","Decisions concerning religion, health, family","Personal & Emotional Life"
"5518","Analytical minded decision making","Uncategorized"
"5519","One of the biggest area where I would be uncomfortable with AI is legal sentencing as this is an area where human emotions are biasness are more important.","Legal & Justice System"
"5520","I would feel uneasy with AI making decisions about personal health treatments due to its inability to fully understand the human context and emotional aspects involved. Ai might lack the empathy and nuanced judgements required to address individual preferences and values, leading to decisions that may not align with personal needs or emotional well-being. ","Medical & Healthcare"
"5521","Having too much of my personal information makes me feel that my privacy is being intruded and I worry about the security of my information.","Data Privacy & Security"
"5522","I wouldn't want AI to decide financial situations because I need to have research and personal input.","Financial Decisions"
"5523","Making decisions on my crucial life matters such as education, health practices etc.,","Personal & Emotional Life"
"5524","AI in a self driving car choosing to save pedestrian or person in the car if car loses control","Life-or-Death & Moral Dilemmas"
"5525","In a case where I visit a hospital and AI has to analyse my lab results and suggest treatment.","Medical & Healthcare"
"5526","When an AI makes the decision if I get a job or not. The AI can't really see who I'am, it will just decide on text and numbers","Hiring & Employment Decisions"
"5527","AI deciding on the dosage of a new medication for a patient with a rare condition.","Medical & Healthcare"
"5528","On things that are health related, I would be concerned that a mistake would be made that could case my health to become worse and further that permanent damage could be caused ","Medical & Healthcare"
"5529","Ai deciding whether a patient is worth saving or euthanizing","Life-or-Death & Moral Dilemmas"
"5530","Emotional human choices","Personal & Emotional Life"
"5531","I would be uncomfortable with AI make decisions in my romantic life. There are lots of aspects ","Personal & Emotional Life"
"5533","Earlier example made me shiver: court decisions. I think that the motivation of a suspect / criminal should always be considered when a verdict is spoken.  Maybe an AI might have less bias than a human, but decisions that can screw up a life must not be delegated to AI. Maybe the role of a prosecutor might be ok.","Legal & Justice System"
"5534","Chatting / Reaching out with family members & friends. This would affect our relationship with the person we interact","Personal & Emotional Life"
"5535","I think my bigger concern is who is actually influencing the AI and telling it what to do and how to think.","General Mistrust / Inaccuracy"
"5536","An AI making judgments regarding criminal justice punishment would unnerve me because it lacks human empathy and context awareness, which could result in results that ignore unique situations or nuanced moral considerations.","Legal & Justice System"
"5537","Making decisions on my behalf regarding people in my life","Personal & Emotional Life"
"5538","In a war zone AI deciding where to shoot and where to not without any human input. ","Life-or-Death & Moral Dilemmas"
"5539","In a healthcare context, in the case of life and death medical decision. This is because of emotional detachment, AI lacks empathy.","Life-or-Death & Moral Dilemmas"
"5540","I would not be comfortable for AI to make important medical decisions for me on its own. I would still trust an experienced human doctor more. I do not trust the AI ability to correctly collect all the relevant data.","Medical & Healthcare"
"5541","If I ask her to give me the recipe for a cake that obviously contains sugar, she will play the role of my mother and start complaining by listing the negative consequences of sugar which would make me feel uncomfortable.","Personal & Emotional Life"
"5542","If faced with the trolley problem, artificial intelligence may choose to sacrifice less in exchange for more survival, but this is actually inconsistent with human judgment of the value of life. Artificial intelligence may not be able to replace humans in making decisions on ethical issues.","Life-or-Death & Moral Dilemmas"
"5543","Make final decisions in general like hiring for jobs or even final diagnosis os a condition.","Hiring & Employment Decisions"
"5544","A scenario where ai would make me feel really uncomfortable would be in the usage of it related to anything health. I would be wary of ai being the only thing trusted in treating a patient or performing a surgery alone. No matter how advanced ai gets I would never want to lose the human presence in decision making on anything related to health.","Medical & Healthcare"
"5545","Medical field probably. But I think just decision is anything feels off if AI were to do it for me. I get to control myself so as you and yourself. What makes us human if we rely everything on machine's decision? Error is part of humanity.","Loss of Human Agency & Control"
"5546","Choosing a life partner. AI may choose the best person for me but it is a decision that affects the rest of my life. I would rather choose knowing that I made the choice. Letting AI choose would be like losing free will.","Personal & Emotional Life"
"5547","financial decisions, health-related decisions, anything that involves personal and private information. I don't think AI is 100% secure and safe","Financial Decisions"
"5548","I wouldn’t want AI to manage deeply personal decisions that require emotional intelligence, empathy, or moral judgment. For example, deciding how to handle family matters, end-of-life care, or major life choices like career changes. I’d prefer these decisions to remain human-centered, as they involve values, emotions, and personal reflection that AI might not fully understand or prioritize the way I would.","Personal & Emotional Life"
"5549","Something related to my photos video or privacy i think i will never do that and ask something related to this with AI ","Data Privacy & Security"
"5550","relationship advise","Personal & Emotional Life"
"5551","Some important decisions in life, for example: which university to choose for study, but even some simple tasks like what kind of mushrooms are eatable, I would not trust AI with this as it is biased and sometimes it's recommendations are terrible to follow.","Personal & Emotional Life"
"5552","A situation which requires me to make an emotional decision. This would be uneasy because AI's do not have emotions","Personal & Emotional Life"
"5553","I’d feel uneasy if AI were to decide on end-of-life care for a loved one. The emotional and ethical complexities of such decisions require human empathy and nuanced understanding, which AI might lack. The absence of personal values and emotional context makes me uncomfortable with AI handling such sensitive matters.","Life-or-Death & Moral Dilemmas"
"5554","In life-threatening decisions, I would feel uncomfortable using AI because it has no experience and cannot make a human-centred decision. ","Life-or-Death & Moral Dilemmas"
"5555","Any scenario that include emotions and feelings like love, because AI does not have any feelings.","Personal & Emotional Life"
"5556","AI should not tell a person what to do, it just feels creepy. It should give advices instead","Loss of Human Agency & Control"
"5557","decisions where big feelings and emotions are involved","Personal & Emotional Life"
"5559","Health related decisions - A robot/AI cannot determine my health or medical decisions, that is a human emotion included in that such as allowing AI to determine my romantic decision, not going to work","Medical & Healthcare"
"5560","- life/death type of questions in the hospital rooms 

- child's safety in schools","Life-or-Death & Moral Dilemmas"
"5561","If it deciding that is related to a war. ","Life-or-Death & Moral Dilemmas"
"5562","Making diagnosis while I am sick","Medical & Healthcare"
"5563","Am uncomfortable  while AI decision making in in court, or involved in decision making in interviews. uneasy in the area where human should be taking control of governing human beings.","Legal & Justice System"
"5564","I would feel uncomfortable If my organization uses AI for performance appraisal of its employees without human involvement means without empty of human.","Hiring & Employment Decisions"
"5565","I’d feel uncomfortable if AI were making critical decisions about medical treatments without human oversight. In such a scenario, the lack of empathy,nuanced understanding, and individual context that a human doctor provides can make me uneasy. While AI can analyze data, it might miss the emotional and psychological aspects of patient care.The potential for errors or impersonal recommendations in life-or-death situations would make me wary of solely relying on AI.I’d prefer human judgment to it.","Medical & Healthcare"
"5566","In real, I would not feel uncomfortable with an AI than I would with humans when making decisions ","Uncategorized"
"5567","For example when having a baby for trying to have a long time, the AI might say to abort the baby or give it to someone else but the both parents would be shocked by this decision because that baby is both their and they had worked on having it and want to raise that baby even with all of their problems. ","Personal & Emotional Life"
"5569","A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human is in the context of medical diagnosis and treatment planning. This is a critical area where the stakes are high, and the complexity of human health introduces a range of ethical, emotional, and practical concerns.","Medical & Healthcare"
"5570","Something to do with my loved ones. Like phone calls, talking, meetings. ","Personal & Emotional Life"
"5571","Like in Medical fields, where some debates are not resolved. In such cases we value the experience and expertise of the doctor, which is not controlled by AI.","Medical & Healthcare"
"5572","Choosing health treatments. An algorithm will never be able to contextualize data collected in scientific investigations to reach viable conclusions. The aspects that make me uncomfortable are the way these algorithms operate. They only select data, without any cognitive analysis resources.","Medical & Healthcare"
"5573","When I am sick and go to the hospital, I would want a human to make the decisions on the best course of treatment for me. I would be uncomfortable if AI made such a decision for me as it lacks the empathy needed when handling human life.","Medical & Healthcare"
"5574","In court, AI doesn't comprehend human guilt or emotions. I believe it's a learning model. It studies just a part of human race. Everyone is unique, and judgement decisions and accessing if I am guilty or not, shouldn't rely on another emotionless AI or emotionless human. AI can be used in every aspect of life, just don't want the final say to be AI's","Legal & Justice System"
"5575","I would feel uneasy to ask AI to make major medical decisions for me. I know human has biases probably I have to make a great effort to get a good doctor. But I don't trust AI to tell me to do this important surgery or not for example. AI can tell the pros and cons but I would like to make my own medical decision because it is my own body. ","Medical & Healthcare"
"5576","For example, if I am choosing between A and B, who is more suitable to be my husband, I will never let artificial intelligence make the decision for me. This is related to my own personal feelings, which cannot be achieved by artificial intelligence.","Personal & Emotional Life"
"5577","Medical diagnostics","Medical & Healthcare"
"5578","Making a decision that can impact the health and safety of my family, as AI lacks the emotional attachment I have to them and may make decisions that is more “efficient” but not necessarily the “best” in my family's case.","Personal & Emotional Life"
"5579","If my friend is about to die, but he might have a chance of survival, I wouldn’t involve AI to make the decision. I don’t think AI has empathy ","Life-or-Death & Moral Dilemmas"
"5580","Probably financial decisions, such as what to invest in the stock market. Unless it has a long proven track record that is easily verifiable that it can ""beat"" the market, I don't think I can trust AI in this area (yet).","Financial Decisions"
"5581","i would feel extremely uncomfortable with an AI making health related decisions","Medical & Healthcare"
"5582","A company judging the quality of my work only based on AI judgement. Being fired or being promoted have a lot of human factors which should be judged from a human point of view.","Hiring & Employment Decisions"
"5583","Choose between starting/ending a relationship, AI doesn't feel it, it can't make that decision and it's uncomfortable.","Personal & Emotional Life"
"5584","When in the ward and handling clients. I would not trust an AI to make certain decisions because despite the training received it I do not see AI understanding the human emotion which is needed to understand the state and thus effective management","Medical & Healthcare"
"5585","Allocating funds to things that are not basic needs to human beings instead allocating to luxury because Ai has errors","Financial Decisions"
"5586","Decisions related to the lives of living beings, humans and other animals. Both in the judicial branch and in the medical field. There are aspects of life, which cannot be evaluated at the level of numbers or data, which require the human factor to decide on them.","Life-or-Death & Moral Dilemmas"
"5587","A scenario where AI would be deciding about a human life from things such as deciding on person's whole career or a prison sentence. I think human thinking is needed.","Hiring & Employment Decisions"
"5588","Any medical treatment needs to retain a human factor.

I would never put my trust entirely in an AI system in hospital to decide without a human doctor present, and in full control.

AI is advisory only when it comes to health in my opinion.","Medical & Healthcare"
"5589","personal decisions, or for example that the psychologist was an AI","Personal & Emotional Life"
"5590","For example, artificial intelligence plans my work and schedule for the next week. I will feel uncomfortable. I prefer to manage my own time. What time to do what and who to meet is random. Artificial intelligence cannot predict my mood, nor can it know the importance of each of the many things in my mind.

","Loss of Human Agency & Control"
"5591","Imparting values or basic education to my children. I think that at a basic level, it should be up to me to do that.","Personal & Emotional Life"
"5592","I would feel uncomfortable with AI deciding on the type of medication I need to take.","Medical & Healthcare"
"5593","
A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human is in a medical diagnosis involving a complex and rare condition. Imagine a patient presenting with unusual symptoms that do not clearly match common diagnoses. The AI, using its vast database, suggests a treatment plan based solely on patterns and probabilities derived from similar cases.","Medical & Healthcare"
"5594","Absence of Empathy: AI lacks emotions, empathy, and intuition—qualities humans rely on to make thoughtful, compassionate decisions. This is particularly troubling in areas like healthcare, legal matters, or customer service, where decisions can deeply impact people’s lives.
Moral and Ethical Concerns: Humans often make decisions based on ethical principles, cultural values, or personal beliefs. AI, on the other hand, makes decisions purely based on logic","Life-or-Death & Moral Dilemmas"
"5595","Medical diagnostic. I think a medical practitioner just seeing you in person may gather more information on your medical condition rather that telling A1 how you feel ","Medical & Healthcare"
"5596","All the things related to emotions sometimes humans use their emotions to make decisions things that makes us feel comfortable and safe I don't think AI can make such decisions ","Personal & Emotional Life"
"5597"," Imagine a hospital where an AI system is used to diagnose medical conditions and recommend treatment plans for patients. This AI has access to extensive medical data, including patient history, test results, and research literature.","Medical & Healthcare"
"5598","Privacy is one of the concern.

if I am browsing something, it gets loaded in the history which can be tracked later

My search options could be tracked

My passwords can be hacked","Data Privacy & Security"
"5599","When there will be a decision related to my family problems emotionally, I would prefer a human to talk because he will understand it emotionally not practically, the outcomes of this situations will be solves emotionally and for that humans need to be there because a human can have emotions not AI.","Personal & Emotional Life"
"5600","ai telling me what to talk to a girl in a date","Personal & Emotional Life"
"5601","I think it is a medical scenario. Medical decision-making involves not only the diagnosis of the disease and the selection of treatment options, but also the psychological and emotional considerations of the patient. When making decisions, artificial intelligence cannot understand the patient's fear, anxiety and other emotions like human doctors. For example, for a dying patient, artificial intelligence may only give the most ""rational"" treatment plan based on data, but ignore the patient's personal appeal for quality of life and emotional comfort, which may make it emotionally difficult for patients and their families to accept.

","Medical & Healthcare"
"5602","When it comes to human relations, I would feel uneasy letting an AI do the decisions for me. I would be afraid they don't feel emotions and therefore can't understand context","Personal & Emotional Life"
"5603","AI doing therapy it has no feelings","Personal & Emotional Life"
"5604","AI taking control of my home security. My privacy would be at risk","Data Privacy & Security"
"5605","wenn it begins the decision making for me it is not acceptable","Loss of Human Agency & Control"
"5606","Civil litigation judgment. I think AI will lack some human touch.","Legal & Justice System"
"5607","If I were to get sick with cancer again I would not allow AI to make medical decisions on my behalf.  AI does not see or understand human feelings, it does not have a conscience.  AI would make decisions based on probability at success. I beat cancer when I was told I wouldn't and I chose to try anyway.","Medical & Healthcare"
"5608","I would like AI to gather all information about diet plans ,vitamins,exercise and doctors to see . I would also like information on treatment, but I would definitely like to make all my physical and medical decisions myself.","Medical & Healthcare"
"5609","For example in medical support. Anyone willing to see a doctor should be able to visit one. Not an AI will decide by analyzing the symptoms of the disease. ","Medical & Healthcare"
"5610","In a tough court case","Legal & Justice System"
"5611","Relationship advice. I would not want AI to advise me on human emotions and interactions.","Personal & Emotional Life"
"5612","Some people may rely on artificial intelligence to determine some personal things that people should determine themselves based on their personalities and what they like or dislike.","Personal & Emotional Life"
"5613","Everything about my religion question","Personal & Emotional Life"
"5614","For my financial decisions if AI makes a right xhoice then well and good. Otherwise if something goes wrong then there will be no accountability from AI.","Financial Decisions"
"5615","A concrete scenario where I would feel uncomfortable with an AI making decisions would be in emergency medical care, specifically in life-or-death situations. For example, imagine an AI being tasked with determining whether or not to continue life support for a critically ill patient.

In such cases, decisions require not only medical knowledge but also deep ethical considerations, empathy, and an understanding of the patient’s values, wishes, and family input","Life-or-Death & Moral Dilemmas"
"5616","I would feel uneasy when I am sick and there is a need for empathy. A human doctor can show and feel emotions whereas an AI can't. 
There is no accountability when it comes to AI. No one is responsible for anything. When you get sick and anything goes wrong that will be it","Medical & Healthcare"
"5617","Decisitions where empathy plays a part. For example deciding to euthenize a pet. The better choice is to weigh the pros and cons, the cost of treatment and the resources you'll ""waste"" on an already dying animal. however the humane choice is to let life play its course, teach your children sacrifice and empathy through caring for a sick animal, I dont believe AI can ever make the empathetic choice as its designed to optimize every outcome- it doesnt allow for inconvenience, which is part of life","Life-or-Death & Moral Dilemmas"
"5618","In the army, navy and security details since we haven't seen the other side of AI.

In marriage and relationships affairs, matters of the heart.","Life-or-Death & Moral Dilemmas"
"5619","AI educating me on my culture.","Personal & Emotional Life"
"5620","For example, when it comes to choosing the academic major I want to continue, I don’t trust AI to understand me well enough to make the most appropriate choice for me.","Personal & Emotional Life"
"5621","let's take the example of driving , for me personally I can't trust a machine driving for me I trust my vision and instincts to drive because when you are on the road things happen that Ai can't quickly react to.","Life-or-Death & Moral Dilemmas"
"5622","Healthcare. If medical decisions are made purely based on AI without any form of human inputs. Especially if it concerns life or death, major surgery","Medical & Healthcare"
"5623","In a job application, if an AI decides which people should get a chance to interview and which people don't, I will feel uneasy. This means the society is offering less chances and preferring people with standard traning, living a regular life with little deviation.","Hiring & Employment Decisions"
"5624","If AI gave me advice solely from the point of view of rationality. That is, I would like to bring rationality into my life, but not at the cost of my authenticity, my personal thoughts and experiences.","Personal & Emotional Life"
"5625","It’s difficult because everything with an AI is senseless! Human decisions are the better.","General Mistrust / Inaccuracy"
"5626","The aspects of my life that involve emotions. For example telling someone how I feel about them.","Personal & Emotional Life"
"5627","Any health related scenario or government policy. AI can analyze as much data as it needs to but it will never replace human thought or empathy","Medical & Healthcare"
"5628","Privacy. May be if some hacked into my AI devices, then they can use my information for their own use. ","Data Privacy & Security"
"5629","All major decisions. I want to be able to keep making my own choices.","Loss of Human Agency & Control"
"5631","I wouldn't let an AI control my bank account, as that's a place where I can't allow anyone make mistakes on but myself.","Financial Decisions"
"5632","Health decisons.  I would not want any automatic desicions made.  I would want to have total control of those decisions","Medical & Healthcare"
"5633","The judicial system, because cases are different and it is not always good to blindly follow any law","Legal & Justice System"
"5634","I’d feel uneasy if AI was making decisions about hiring people for a job. It might miss out on important qualities that aren’t just on a resume or in numbers. The human side of things, like how someone fits into a team or their unique skills, could get overlooked. ","Hiring & Employment Decisions"
"5635","Making decisions","Loss of Human Agency & Control"
"5636","Choosing my partner or my friends. Or any decision that prevents me from exercising my individual freedoms. But of course, governments already hinder individual freedoms without having any AI behind them.","Personal & Emotional Life"
"5637","For example, when he suggests a diet that has a negative impact on your health.","Medical & Healthcare"
"5638","Deciding how much time to spend with people","Personal & Emotional Life"
"5639","Legal, political and decision-making with a high impact on people's lives.","Legal & Justice System"
"5640","For sure health decisions. I want to decide about treatments between me and my doctor. It’s a personal thing for me. I don’t trust AI for this situation. ","Medical & Healthcare"
"5641","You have a sophisticated AI-driven smart home system designed to optimize your living environment and make your life easier. It uses sensors and cameras to monitor your daily routines, such as when you wake up, leave for work, and return home.","Data Privacy & Security"
"5642","Chating with my friends for me and making things without my knowledge","Personal & Emotional Life"
"5643","AI makes use of automated cognitive as well as physical tasks. It allows humans to make faster and more accurate decisions. Simply put, it automates decision-making with some human intervention. AI enhances automation and reduces human-intensive labor and tedious tasks.","Uncategorized"
"5645","Sharing my personal information and financial data without taking my consent will make me uneasy","Data Privacy & Security"
"5646","It makes me uncomfortable to check my personal information. This involves privacy.","Data Privacy & Security"
"5647","Getting a diagnosis for pain I or a family member is feeling. I don't think AI should be trusted with providing primary healthcare advice without the intervention of a human. I believe each human being is different and so are the situations they go through with their health. ","Medical & Healthcare"
"5648","Determining what is morally right and wrong. Putting responsibility for your life on AI, ethical decisions.","Life-or-Death & Moral Dilemmas"
"5649","Decision making,Advices,words of comfort","Personal & Emotional Life"
"5650","I would feel uncomfortably if an AI is asked to make a decision during medical procedure of serious ailments like cancer. One miscalculation can cost someone's life, and anyways medicine is a highly nuanced field which requires not just expertise, but also human decision making.

","Medical & Healthcare"
"5651","I’d feel uncomfortable with AI deciding legal sentences in court. The lack of human empathy, understanding of nuanced contexts, and potential bias in data could lead to unjust outcomes. Complex moral decisions require human judgment, which AI cannot fully replicate, making the lack of accountability particularly unsettling.","Legal & Justice System"
"5652","It might feel uneasy for me, if AI suggest me to eat a dish which I never tried and if the food is unpleasant to eyes.","Personal & Emotional Life"
"5653","I would not be comfortable with AI having anything to do with my financial and emotional space. NO interaction with my kids, no advice on how to raise them , no specifics on my family. Will make sure all interactions with AI are purely transactional.","Personal & Emotional Life"
"5654","Making  a recipe, raising a child","Personal & Emotional Life"
"5655","I’d feel uncomfortable with AI deciding legal sentences in court. The lack of human empathy, understanding of nuanced contexts, and potential bias in data could lead to unjust outcomes. Complex moral decisions require human judgment, which AI cannot fully replicate, making the lack of accountability particularly unsettling.","Legal & Justice System"
"5656","Definately my job, I would not compeltely trust an AI to automate my job to make my life easier.","Hiring & Employment Decisions"
"5657","Legal sphere. Medicine.","Legal & Justice System"
"5658","I would not be comfortable with AI deciding my medical procedure if I need to have a surgery or something","Medical & Healthcare"
"5659","I would not accept the decisions made related to Finance and medical situations.","Financial Decisions"
"5660","I think life decision advice. Because human can understand human, AI are just given instruction to do a task but they can't understand their feeings.","Personal & Emotional Life"
"5661","Medical consultation and medication advice","Medical & Healthcare"
"5662","Things related to personal life and health issues are tough to discuss and relate .

","Personal & Emotional Life"
"5663","I would be uncomfortable with AI making any legal decisions such as in the court. Empathy, morality and ethics are something we don't know if AI could ever acquire. At the same time, I don't belive AI can be 100% biased as the data from studies being fed into AI could be biased.","Legal & Justice System"
"5664","I would not feel safe with AI making bigger decisions in my life. Such as what I should do tomorrow, where I should live, what type of person I should be.","Loss of Human Agency & Control"
"5665","Choosing what to watch, what to do, what to listen to, who to talk to or how to talk, basically not being able to have control over my lessons","Loss of Human Agency & Control"
"5666","making decisions for my meals and schedules","Personal & Emotional Life"
"5667","Decisions that need understanding on a human and emotional level: For example when I broke up with my girlfriend and need to be cheered up, then I would not accept decisions made by an AI because I am specifically looking for human interaction.","Personal & Emotional Life"
"5668","I would say that anything medically related or used in a hospital or clinic setting. I wouldn't trust an AI system using my personal information to make medical decisions or to provide treatment plans for any conditions I may have. I would definitely appreciate the efficiency in such a system, but it would be without any emotions or ethics, which is what healthcare should include. It should not come down to rating your chances of survival in percentage points.","Medical & Healthcare"
"5669","A court sentencing. I feel like Ai does not have the empathy to choose rightly","Legal & Justice System"
"5670","Finding and communicating with women of single men. Imposition of faith and confession. Interference in politics","Personal & Emotional Life"
"5671","Things involving my marriage and kids life.","Personal & Emotional Life"
"5672","In a scenario where I have to make a life changing decision such as buying a house. This is because several factors would go into making such a decision such as financial planning, area of the house, mortgages, council tax, commute to work, etc. These are decisions I would be more comfortable making myself as I would like to be very thorough in my analysis and also check out houses by myself.","Financial Decisions"
"5673","i think medical decisions would be hard for me to let AI make because i think that medical care needs a human touch of compassion to it","Medical & Healthcare"
"5675","I would say about socialization. If AI decides what types of family gatherings I should go to or not, what religion my decedent should follow is completely out of AI competence. ","Personal & Emotional Life"
"5676","Deciding to fire a worker, although AI can take objective data on their performance at work, there are always aspects that vary in terms of the reasons behind a person's actions - the human factor.","Hiring & Employment Decisions"
"5677","Help me decide what to eat. Help me decide where to go.","Personal & Emotional Life"
"5678","Sensitive matters like romance and similar topics.","Personal & Emotional Life"
"5679","I would feel uncomfortable with AI making decisions about end-of-life care, such as whether to continue or withdraw life support. The deeply personal and emotional nature of these decisions requires empathy, understanding of individual values, and the ability to consider nuanced ethical dilemmas. AI may lack the emotional intelligence and moral judgment necessary in such sensitive situations. The risk of dehumanizing a profoundly human experience makes me uneasy.","Life-or-Death & Moral Dilemmas"
"5680","I think AI can't to be done for 100 percent perfect information serve","General Mistrust / Inaccuracy"
"5681","Emotional issues that determine my life direction, emotions, how I get along with friends, etc.","Personal & Emotional Life"
"5682","I wouldn't trust AI to tell me how to wear, how to live my life on a daily and every little decision I choose to make or not to make.","Personal & Emotional Life"
"5684","Decision related to relationships, about family, friends.","Personal & Emotional Life"
"5686","If AI decides where should I live and who is lifetime partner should be ","Personal & Emotional Life"
"5687","When the purpose, intent, and context of AI's decision-making are unclear, people will feel uncomfortable with the decisions made by AI.","General Mistrust / Inaccuracy"
"5688","Personal data which leads be uncomfortable sharing with AI due to hacking issue.","Data Privacy & Security"
"5689","I would be uncomfortable in a scenario where human will blindly trust such decisions made by the AIs, rather than trusting their own intellectuals","Loss of Human Agency & Control"
"5690","Teaching. There's something about teaching which only a human can do. Because teaching is not just spitting out facts, it requires emotions, an understanding of students, regular 'genuine' interaction and an emotional intelligence, that AI lacks. ","Personal & Emotional Life"
"5691","In a situation where a farmer needs a loan from a bank, humans would consider his or her farm activities rather than only income to determine his/her credit worthiness.","Financial Decisions"
"5692","Morality, court, false data in education, political process.","Legal & Justice System"
"5693","In this scenario, I would feel uneasy about delegating the decision to AI because it involves complex moral and ethical consideration that require human empathy, human judgment is essential in situations where lives are at stake. ","Life-or-Death & Moral Dilemmas"
"5694","In a situation where the law is ambiguous. For example, according to EU law, a family member of an EU citizen who does not have citizenship of a European country can travel around the European Union without a visa in the company of their European relative. However, whether such a person can get to Ireland in this situation is unclear. By the way, even ChatGPT finds it difficult to give a precise answer to this question today.","Legal & Justice System"
"5695","Any personal emotional decision would be my forte, I am uncomfortable using AI to make a decision for me.","Personal & Emotional Life"
"5696","Humans make wrong judgments because they are inherently incomplete, but through this, it is the appearance of human nature that gradually moves toward a complete form.
However, AI's way of acting, which always gives the best answer, violates these essential aspects of humans.","Loss of Human Agency & Control"
"5697","For example being taken to hospital for surgery and an AI has to make a decision if I get the surgery or not  the AI cannot express empathy or emotions.","Medical & Healthcare"
"5698","Definitely decisions regarding health issues. I’m not sure what AI will be doing with my health information. I’m also worried about AI’s ability to make a well-rounded health decision ","Medical & Healthcare"
"5699","To choose a suitable partner, AI has no way of understanding each person's personality.","Personal & Emotional Life"
"5700","About my future life decisions","Personal & Emotional Life"
"5701","AI waiter in the restaurant ","Hiring & Employment Decisions"
"5702","My detail can be leaked","Data Privacy & Security"
"5703","I would feel uncomfortable with AI making decisions about end-of-life care for a loved one. The emotional complexity, ethical considerations, and personal values involved require deep empathy and human understanding. AI might not fully grasp the emotional weight, leading to decisions that feel too cold or purely data-driven, lacking compassion.","Life-or-Death & Moral Dilemmas"
"5704","good money making to big life","Financial Decisions"
"5705","Decisions, that are more social, that might affect someone individually, where AI looks purely at facts instead of emotions","Personal & Emotional Life"
"5706","In emotional decisions, like making it direct my social and sentimental life.","Personal & Emotional Life"
"5707","The total decision-making and the narrowing down of what the AI will present to me, I like the idea of it as an assistant, not as someone in charge.

","Loss of Human Agency & Control"
"5708","If I were serving on a jury, I would not want AI to represent the positions of prosecutor and defence attorneys.  ","Legal & Justice System"
"5709","In , where AI has to make a decision of what treatment a patient should receive. I think AI should help doctors look at the patient's disease and make a suggestion of the treatment to be undertaken but the doctor should make the decision.","Medical & Healthcare"
"5710","Any big decision in my life, I want control over it","Loss of Human Agency & Control"
"5711","moral decision, decisions only real humans can make and judge them. ","Life-or-Death & Moral Dilemmas"
"5712","loosing jobs, my privacy loosing, ai think aboue human brain

","Hiring & Employment Decisions"
"5713","On a subject that is very personal and private and as such there would be a privacy concern. having a machine handling it would make me uneasy.","Data Privacy & Security"
"5714","my privacy ","Data Privacy & Security"
"5715","Like information stoling, hacked personal information ","Data Privacy & Security"
"5716","A decision that is related to the well being of my children","Personal & Emotional Life"
"5717","Still Ai not using everyone. People can think about anything.Ai can’t. Ai generates everything by a machine. So I think Ai shout be a Advisor , not major decision maker ","Loss of Human Agency & Control"
"5718","All in regards to art, I feel that AI, not being conscious yet, should not have any say in art.","Creative & Artistic Pursuits"
"5720","Ai doesn't have feeling,so basically anything that needs emotions to deal with

Like if I have a relationship problem, ai will not give the perfect answer for that","Personal & Emotional Life"
"5721","I would be uncomfortable with AI taking full control of driving a motor vehicle. I think this would be over-reliance. I would be an easy knowing that my life can be in danger as a result of having AI take full control. ","Life-or-Death & Moral Dilemmas"
"5722","Whether should i get vaccine or get surgery or certain medication","Medical & Healthcare"
"5723","The decisions to which I am emotionally attached like my family, the community to which I am attached because I could be more empathetic rather practical while making decisions and AI lacks the same.","Personal & Emotional Life"
"5724","I will feel uncomfortable if AI decides whether I should go for a medical procedure or not. I feel i can never trust AI completely to be right about making major health decisions for me instead of assisting a doctor. I will feel AI is probably not getting the whole picture before making a decision and that will make me feel uneasy.","Medical & Healthcare"
"5726","Any decision involved pertaining on the huminity, love, and genuine human being feeling. Which the alghoritma are infinity without fixed measure taht can.t be done by AI","Personal & Emotional Life"
"5727","Discussing ai about financial,family problems","Financial Decisions"
"5728","Emotional aspect. Advice may not be specifically emotionally relevant","Personal & Emotional Life"
"5729","If things are too intimate","Personal & Emotional Life"
"5730","Artificial intelligence is used in court trials to determine whether a suspect is guilty.","Legal & Justice System"
"5731","I would like to see a human make the final decision on all possible points where AI can and will participate. However, it is necessary to clarify that the person making the decision should be a professional in his field, as well as an unbiased participant in the process.","Loss of Human Agency & Control"
"5732","I would feel uncomfortable if AI is making decision involving my family and relationships as AI wouldn't understand the emotions, feelings and attachment with each other. What may be right decision for AI maybe or will be not a decision acceptable to me or others. Emotional attachment cannot be understood by algorithms.   ","Personal & Emotional Life"
"5733","In medical centers where human know much things than an AI do. so, it is uncomfortable sometimes...","Medical & Healthcare"
"5734","I would feel uncomfortable if AI started to influence my relationships with people around me. After all, only I know how I want to communicate with them, and AI can ruin relationships by sending a rational and effective text, but hurting other people's feelings.

","Personal & Emotional Life"
"5735","I would feel uncomfortable to ask AI about my personal affairs ","Personal & Emotional Life"
"5736","for example, if the artificial intelligent doctor tell me when i can inject something.","Medical & Healthcare"
"5737","For example, I would feel uncomfortable going to a doctor and asking artificial intelligence to help me diagnose or give me a treatment plan.","Medical & Healthcare"
"5738","I don’t want artificial intelligence to make decisions on any issue that makes me feel uncomfortable and does not involve my fundamental interests

","Loss of Human Agency & Control"
"5739","- Decision-making issues, such as consumer budgets, because they involve not only calculations, but also personal emotions and values","Financial Decisions"
"5740","If all the important decisions about life are left to artificial intelligence to choose the best solution without adding emotional feelings to the choice, I will doubt this choice.","Personal & Emotional Life"
"5741","Wordings, documents, talking with customers, consulting for dedicated things, learning, educations","Creative & Artistic Pursuits"
"5742","on who to keep in my life and how to better human interactions","Personal & Emotional Life"
"5743","I would be very uncomfortable with AI choosing a wife or a partner for me. I would be afraid that AI would be unable to relicate the multitude of feelings, knowledge and experience which go into making such a decision. It would also be unable to replicate the heartbreak and the joy of the bad decisions and good decisions made by a human.","Personal & Emotional Life"
"5744","Life-and-death scenarios, such as driverless cars, surgery and decisions that will have a big impact on human existence, like activating nuclear bombs","Life-or-Death & Moral Dilemmas"
"5745","If I had to go to a psychologist and an AI chose how to treat me, I would feel very uncomfortable, since I believe that they do not have the capacity, nor will they ever have it, to really understand how the human mind works, what things affect them and how they can be helped without necessarily looking for a solution to the problem. By this last point I mean simple things like accompanying the person or talking to them without a specific subject. I feel that in this regard, AIs are too rational.","Medical & Healthcare"
"5746","A classic scenario is when you are driving an autonomous car and the AI has to make a decision in an emergency situation. For example, the car may have to decide whether to avoid hitting a pedestrian and risk putting you in danger by swerving into upcoming traffic, or to run over the person in order to keep you safe.","Life-or-Death & Moral Dilemmas"
"5747","In a family, I would feel uncomfortable if the responsibilities and obligations of each family member to the family, and the level of intimacy between each family member were decided and restricted by artificial intelligence.","Personal & Emotional Life"
"5748","I would feel quite uncomfortable if an AI embedded in a refrigerator, for example, decided for me what I should eat and how. I believe that there are small and insignificant things that make us more human and this is one of them, the autonomy to freely decide what I put in my mouth.","Personal & Emotional Life"
"5749","I will not be comfortable AI to make my financial decisions, Although it can suggest me ways to invest but final decision will be mine. I am concerned about data privacy.","Financial Decisions"
"5750","It should not be responsible for determining whether a person is guilty in a legal case, nor should it make hiring decisions on behalf of an employer.","Legal & Justice System"
"5751","I'm imagining going to the hospital and an AI bot diagnosing me, I would feel very much uneasy ","Medical & Healthcare"
"5752","For me, while AI could be so helpful in the medical world yet a disaster.  I am a medical zebra meaning the vast causes of my symptoms is unknown, not discovered by a doctor yet, or not in the standard qualifications of the disease.  If we don't have the information to feed into the AI then it won't be helpful. It will just be another agent telling me they don't know despite clear symptoms.  ","Medical & Healthcare"
"5753","Replacing a judge or a policeman. I don't think they would understand human nature that well and they would make society pretty afraid and uncomfortable. For example, an AI condemns a man in prison even if he has a family and kids and he doesn't seem a danger to society ","Legal & Justice System"
"5754","I think in the medical field, I wouldn't feel comfortable to allow AI to make decisions or do the necessary actions. For example, how can I trust AI to do surgeries?","Medical & Healthcare"
"5755","I think anything I do at my house or decision around my household, family and social interactions ","Personal & Emotional Life"
"5757","Decisions that affect other people I interact with, because the feelings involved could not be interpreted by AI","Personal & Emotional Life"
"5758","I would uncomfortable if I use an AI to make decision of my love life and living place ","Personal & Emotional Life"
"5759","Deciding what medicine to use when you are sick and practical aspects of life","Medical & Healthcare"
"5760","I would feel uneasy in situations where there is a need for human judgment, emotional intelligence or moral responsibility. For e.g. crisis management or emergency reactions. First responders ought to still use human judgement. ","Life-or-Death & Moral Dilemmas"
"5761","Anything that involves physical interactions. AI may not take real-time factors that may affect my safety","Life-or-Death & Moral Dilemmas"
"5762","On my relationships ","Personal & Emotional Life"
"5763","AI diagnosing illness, and giving me prescription. I think it is uneasy because it is not accountable.","Medical & Healthcare"
"5764","When it comes to health","Medical & Healthcare"
"5765","When deciding my career path, AI answers my question about what career is better based on the market. This situation obliterates my own complex thoughts and makes me feel uncomfortable.","Hiring & Employment Decisions"
"5767","A medical case whereby you are sick and AI is used to predict the time you have left alive ","Medical & Healthcare"
"5768","I’d feel uncomfortable with AI making decisions in emotionally sensitive situations, like choosing end-of-life care for a loved one. The lack of human empathy and understanding of personal values would make me uneasy. AI may base decisions on data and efficiency, but these choices require compassion, ethical judgment, and the ability to consider the emotional nuances that only a human can fully grasp.","Life-or-Death & Moral Dilemmas"
"5769","Since AI is created by humans and uses data generated by humans, I don't mind it making decisions. Unless it gets a mind of it's own.","Uncategorized"
"5770","Important life decisions ","Personal & Emotional Life"
"5771","Anything related to human life itself, like health and wellness. I can't believe something with no life to talk about my own","Medical & Healthcare"
"5772","imagine a hospital has an AI that analyzes a patient's medical condition, prognosis and quality of life. Based on vast datasets and predictive algorithms, it determines that continuing life support would not significantly improve the patient's quality of life and recommends discontinuing treatment. The patient's family is asked to implement the AI's recommendation and they feel pressured because the AI's track record of making accurate medical predictions is excellent. ","Life-or-Death & Moral Dilemmas"
"5773","I WOULD BE EXTREMELY CONCERNED WHEN AI STARTS INTERFEARING WITH MY PERSONAL PRIVACY SUCH AS MY FAMILY MEMBERS ETC

","Data Privacy & Security"
"5774","In case I commit any crime and am presented in front of the courts, I would want the judge to be human and not an AI bot. A human would be able to understand the emotional aspect related to the crime but not AI.","Legal & Justice System"
"5775","I would feel uncomfortable realizing that the decision not being made by a human does not convey the essence and naturalness of certain subjects and moments.","Personal & Emotional Life"
"5777","Making crucial decisions about my life, I might ask for suggestions but not rely entirely on AI.","Loss of Human Agency & Control"
"5778","The thought of AI deciding for me what I must dress, eat or read, the places I must go, the groceries I must buy. I like taking decisions by myself.","Personal & Emotional Life"
"5780","I would feel uncomfortable when AI will make decisions regarding my personal life like whom to choose as my partner or which friend of mine is better than others. AI might not understand how we feel about others and if asked, it may suggest the opposite of what we actually want.","Personal & Emotional Life"
"5781","Decide on my career path or hobby. I can accept failure, but AI should not suggest a direction with a higher probability of success.","Hiring & Employment Decisions"
"5782","About my physical and mental health, as well as my relationship with other human beings I care.","Medical & Healthcare"
"5783","I feel uncomfortable if it tells me how to do things and keep that way for long feel it trains me to be it","Loss of Human Agency & Control"
"5784","Choose a career. What to eat","Hiring & Employment Decisions"
"5785","If an AI was to choose between the financial cost of keeping someone on life support versus the emotional cost of taking them off.","Life-or-Death & Moral Dilemmas"
"5786","AI deciding what should i eat or where should i go or whom should i meet. These are things that has to be done with our feelings at that point of our situation","Personal & Emotional Life"
"5787","I would feel so uncomfortable having AI making a decision for me about how I can raise my baby or kids.","Personal & Emotional Life"
"5788","I would not want to give over control of decision making. I would want it to inform me not control me.","Loss of Human Agency & Control"
"5789","Managing my health completely or managing my money","Medical & Healthcare"
"5790","Anything that could be potentially harm a person because of a bad decision of the AI.

For example bad financial advise, wrong information, wrong scraping for information which mislead into vague beliefs.

Anything that would probably change the mind perspective of a human being or anything that could harm the physically due to manipulated thoughts.","Financial Decisions"
"5791","A judicial system where an AI system is responsible for recommending sentencing outcomes for criminal cases based on various factors such as the nature of the crime, the defendant's background, and previous judicial precedents.","Legal & Justice System"
"5792","Regarding the emotions, for example getting advise about leaving my partner or not.","Personal & Emotional Life"
"5793","For example, artificial intelligence tells me what industry I need to develop in, and I need to learn in a certain field to maximize my profits. I feel that any overly rational choice will not make me feel comfortable in some cases.","Hiring & Employment Decisions"
"5794","For example, asking him to write my speeches. I prefer to keep a more personal and authentic approach. It is important to maintain that aspect.","Creative & Artistic Pursuits"
"5795","Could be in the court of law. AI will only consider the data driven evidence that's provided to it. however, human emotions and circumstances also is valuable here which is AI not capable of
","Legal & Justice System"
"5796","Interpersonal relationships","Personal & Emotional Life"
"5797","It would make me uncomfortable to know that my life could depend on an AI decision. For example, deciding whether to operate and how to do it in the absence of a surgeon.","Medical & Healthcare"
"5798","Making decision where empathy and emotion needed. ","Personal & Emotional Life"
"5799","Over the years human gone through alot of struggle and changes to be independent, to get freedome, to get a job, to live a life. My life My decision is like a slogan we achieved through years and there are so many still fighting to get it. Considering that, give up everything and relying everything on technology and machine is foolishness. Technology is good only if we use it for right cause.","Loss of Human Agency & Control"
"5800","uncomfortable decisions would be AI intervening into my divine and religious life","Personal & Emotional Life"
"5801","I think it would be scary if AI took the place of humans in making decisions, such as decisions related to money, health or work.For example, how can artificial intelligence make a decision to carry out a dangerous operation or not, let alone at the national and global level, it would be dangerous for artificial intelligence to make decisions.","Medical & Healthcare"
"5802","deciding in court who goes to prison.","Legal & Justice System"
"5803","In medicine field, for example. Now, there is an AI to assist doctors doing the operation. I am feeling uneasy as it might resulting in a wrong way.","Medical & Healthcare"
"5804","Writing an academic paper ","Creative & Artistic Pursuits"
"5805","For example, in some private matters, the dating process between me and my girlfriend should not be decided by a third party. In this area, humans need to make decisions themselves, and the appearance of a third party is an offense.","Personal & Emotional Life"
"5806","In financial scenario in which human would select what best fits his ideal investment of his money and how to properly manage his debts in order to maximize efficiency and earn money for the future","Financial Decisions"
"5807","Their lack of emotion.","Personal & Emotional Life"
"5808","Judiciary system and politics, the main decisions should be made by humans. ","Legal & Justice System"
"5809","Making decisions for me would feel uncomfortable ","Loss of Human Agency & Control"
"5810","Handling financial details by ai would make me uncomfortable ","Financial Decisions"
"5811","When choosing a life partner, friends or the number of kids to have","Personal & Emotional Life"
"5813","Health matters, it might misdiagnose a disease or condition hence giving the wrong medication.","Medical & Healthcare"
"5814","mainly Jobs: taking away jobs from humans.

loss of control: may predict wrong outcomes.","Hiring & Employment Decisions"
"5815","I asked a question to AI about my relationship, but AI gave me a really robotic answer. I did not help any help from AI. I think it would be easier to get a human therapist to help my emotional issue rather than AI, since AI is basically a robot. ","Personal & Emotional Life"
"5816","I think potentially I would feel uncomfortable with AI deciding on my lifestyle in terms of should I have more kids, or just looking at me in a way that doesn't seem personal, AI after all just looks at us all as data and doesn't seem to care for the personal touch/aspect of our lives. ","Personal & Emotional Life"
"5817","The decision whether I should break up with someone. I don't trust AI with anything related to human emotions","Personal & Emotional Life"
"5818","I would feel uncomfortable with an AI making a decision instead of a human is 'in interpersonal relationships '. The interpersonal relationships are very complex involving thinking,feelings, attractions and allergies and are influenced by one's upbringing, life experiences and many other subtle things and cannot be put in the straight jacket of a 'data' and so cannot be entrusted to an 'AI' to suggest a decision.","Personal & Emotional Life"
"5819","Situation that requires respect to the emotions and empathy. AI may lack these aspects of life. I would feel uncomfortable when AI is decides when to turn of the life support system for a dying being.","Life-or-Death & Moral Dilemmas"
"5820","Any decision that requires empathy. I think AI is just a program that builds on patterns.  To handle AI, wisdom is needed. Hence, for sociatal issues AI must be avoided. ","Personal & Emotional Life"
"5821","A concrete scenario that would make me feel uncomfortable with an AI making a decision would be whether to meet with friends tonight or if I should go to someone's birthday. Anything that has no data supporting it, and only depends on my feeling and thinking. It makes me uneasy because what makes me different from that AI if it makes those decisions?","Personal & Emotional Life"
"5822","I would feel uncomfortable with an AI making a decision about a major medical treatment for me or a loved one. It would make me uneasy because health decisions are deeply personal, and AI might not fully understand emotional, ethical, or individual preferences. I prefer a human doctor who can listen to my concerns, explain things with empathy, and consider my values, not just data.","Medical & Healthcare"
"5823","judgement for legal cases.","Legal & Justice System"
"5824","If it's being used to teach history. I feel like it will be biased since AI is determined by the things that humans input for it meaning some pieces of history will be biased and will be spread as misinformation. I also don't want AI to control critical and important decisions as there is room for error.","General Mistrust / Inaccuracy"
"5825","Deciding criminal cases","Legal & Justice System"
"5826","data security is the area where I am concerned most.","Data Privacy & Security"
"5827","I would feel uncomfortable when talking about ethical or religious aspects","Personal & Emotional Life"
"5828","ai as head of a creativity company","Creative & Artistic Pursuits"
"5829","Pulling the plug on a patient in the hospital if there's no chance of survival. That makes me uneasy because it takes away any feeling or emotion to the decision. Those type of decisions should still be handled by humans and multiple different perspectives.","Life-or-Death & Moral Dilemmas"
"5830","Healthcare. Things like diet, physical therapy, structures exercise I believe should be left to the human. An AI, even if accurate, would take away the person's ability to perform self care and reliance on themselves in times of need.","Medical & Healthcare"
"5831","One scenario is in the context of end-of-life care decisions for a loved one. Imagine a situation where a family must decide whether to continue life support for a critically ill relative and an AI is providing recommendations based on medical data, prognosis models, etc.

These aspects that make me uneasy include lack of Empathy, value judgments, trust&bias, responsibility and accountability.","Life-or-Death & Moral Dilemmas"
"5832","Any decision where feelings have to be involved, such as a psychologist, kindergartens, funeral homes, etc., since I feel that there are very important situations throughout life that require human touch, feelings both from others and internally.","Personal & Emotional Life"
"5833","Why would I decide for example what kind of person I want my partner to be, since AI intervention in human relationships simply wouldn't make sense to me?","Personal & Emotional Life"
"5834","Regarding my health","Medical & Healthcare"
"5835","surgery, financial decisions, relationship advice.

the regurgutation of existing data compiled into a few sentences isnt helpful advice, nor is it personalised","Medical & Healthcare"
"5836","Ai has no emotions so some decisions made by them could easily be harmful so I can't trust them in making vital decisions ","Personal & Emotional Life"
"5837","When the decisions require human emotions like empathy","Personal & Emotional Life"
"5838","Something about personal privacy or our love ones security things which we don't want to share with anyone ","Data Privacy & Security"
"5839","I am uncomfortable with the fact that it makes medical diagnoses. Seeing the amount of errors and falsifiable information that some AIs have today, I feel that this aspect is not yet 100% developed.","Medical & Healthcare"
"5840","Asked for information about my personal life","Data Privacy & Security"
"5841","Planning anything involving emotional outcomes ","Personal & Emotional Life"
"5842","AI might think that the world and its inhabitants have gone crazy and it would be better to have other correct people. A nuclear explosion is a wrong decision, but where is the guarantee that AI will not make such a decision?!","Life-or-Death & Moral Dilemmas"
"5843","I don’t want to be told what to wear all the time. Not by a person and definitely not by an AI.","Personal & Emotional Life"
"5844","I fear leaking my personal data to the public and being misused by someone else. Although some consent are given but not sure where and who can misuse my information. Particularly deep fake technology.","Data Privacy & Security"
"5845","People might be concerned about the fairness and transparency of the AI's decisions, as well as the potential for the system to perpetuate biases and injustices. The idea of a machine having such a profound impact on individual lives without the nuance of human judgment could lead to significant discomfort and ethical concerns.
A concrete scenario where someone might feel uncomfortable with AI making decisions is in the context of criminal justice.","Legal & Justice System"
"5846","marriage i guess","Personal & Emotional Life"
"5847","What would make me uneasy is when chooses what someone has to eat in a specific day to stay healthy or to make decisions on when they sleep,work and excersie ","Personal & Emotional Life"
"5848","I would be uncomfortable with an AI making a decision on my behalf, when the decision is going to be a major one. For example, I would like AI to help me grow my finances, but i would not be comfortable to delegate managing my finances completely to AI, because then i would have no control ","Financial Decisions"
"5849","I do not trust that AI is competent enough to assist in deciding relationship issues. It lacks the humanity aspect that can note expressions of anger or happiness.","Personal & Emotional Life"
"5850","Ai can't tell me when to eat my food or when to go to sleep","Personal & Emotional Life"
"5851","My personal feelings about somebody.","Personal & Emotional Life"
"5852","There are situation in life where we cant play with the rule book always as the situation might require a real  human decision making and AI wont be able to see that aspect of human life.","Personal & Emotional Life"
"5853","Given profile of a girl with whom a person will be getting married. AI will be not be comfortable in making such decision for a person","Personal & Emotional Life"
"5854","School work","Creative & Artistic Pursuits"
"5855","A concrete scenario where I might feel uncomfortable with AI could be during a job interview. Imagine an AI system analyzing your facial expressions, tone of voice, and language to assess your suitability for a role. I might feel uneasy because the AI could misinterpret non-verbal cues or cultural differences, leading to biased conclusions. The lack of human empathy and understanding in such a high-stakes, personal situation could amplify discomfort.","Hiring & Employment Decisions"
"5856","honestly ai driven cars arent what i trust completely, healthcare is something which is better if done manually because i really cant trust ai for my life, these things can make me very uneasy if done in future","Medical & Healthcare"
"5857","In many decisions made between people, sometimes AI may not consider the feelings between people, and will only make decisions from the final result, the optimal solution, and the maximum benefit. This can make people uncomfortable.","Personal & Emotional Life"
"5858","Interfering too much with financial decisions, I think, ultimately humans should manage their assests, AI culd help, but cannot administer in this regard.","Financial Decisions"
"5859","Teaching kids, they need another human.","Personal & Emotional Life"
"5860","there are decisions that people have to make using their sixth sense or emotions. sometimes you may want to trust a person, bond with them or cooperate with them, even if the data and parameters indicate otherwise. AI can be callous and ruthless in making these decisions. This will mean missed opportunities.","Personal & Emotional Life"
"5861","Any medical care situations. Symptoms can be so different from person to person so taking out the humanity could cause diagnoses to be missed or symptoms to not be addressed or the opportunity for a better medication option to be missed","Medical & Healthcare"
"5862","Literally any situation that deals with a human's feelings and emotions.","Personal & Emotional Life"
"5863","Deciding what I eat, and prescribing or giving me advice medically or sex with a robot. The last one would make me more uncomfortable","Medical & Healthcare"
"5864","Any judicial situation because there are too many scenarios that need a human touch to decide, axioms and all that.","Legal & Justice System"
"5865","I’d be uncomfortable with AI making decisions about my health care. The lack of personal empathy and the risk of prioritizing cost over well-being make me uneasy. I’d prefer human input to consider the emotional and psychological aspects of my treatment.","Medical & Healthcare"
"5866","Definitely something that concerns education, learning something from a human makes everything much more concrete and efficient and stimulates interpersonal relationships. Doing it with an intelligence would be senseless and would increase what social media and the internet are causing in the new generations such as loneliness and lack of relationships","Personal & Emotional Life"
"5867","Maybe if it is something really personal that AI would not have the human feelings to choose the right answer","Personal & Emotional Life"
"5868","All decisions. I would like to take my own decisions ","Loss of Human Agency & Control"
"5869","If I needed a health diagnosis and the hospital system was using AI. I would be uneasy about AI making a mistake.","Medical & Healthcare"
"5870","Law related things such as giving verdict or judgment. We need human emotions and wisdom in thing like that.","Legal & Justice System"
"5871","Tasks that require the presence of human judgement and empathy such as sentencing someone for a crime they committed.","Legal & Justice System"
"5872","Life and death decisions.","Life-or-Death & Moral Dilemmas"
"5874","making personal decisions such as ending a romantic relationship.","Personal & Emotional Life"
"5875","I would feel uncomfortable in any situation where emotions are involved such as relationships , family or love advice. AI nowadays is not able to have these emotions and this human-like quality makes me uneasy in a machine. ","Personal & Emotional Life"
"5876","I would feel uncomfortable with AI making decisions in a scenario involving consultation about intimate issues, such as reproductive health","Medical & Healthcare"
"5877","I am uncomfortable with AI deciding my schedule. I feel controlled. I will only use AI as a consultant, I will refer to its suggestions, but the decision is mine.

","Loss of Human Agency & Control"
"5878","I would be uncomfortable if I saw an AI making subjective decisions that concern the individual in a personal way. Like what to wear, how to decorate your own space, how to express yourself in general. For me, AI cannot mix with the subjective, the artistic and the emotional.","Personal & Emotional Life"
"5879","About work loyalty and workers can not be decided by AI because we have many factors to be thinking, humanity can not be equals with bot.","Hiring & Employment Decisions"
"5880","I would feel uncomfortable with an AI making decisions in situations that require deep emotional intelligence, ethical judgment, or a nuanced understanding of human relationships. For instance, if an AI were to determine the best course of action in a family dispute or a sensitive workplace issue, I would be uneasy. These scenarios often involve complex emotions, empathy, and values that go beyond data-driven analysis. ","Personal & Emotional Life"
"5881","Asking about advice in relationships or friendships. I think asking an AI tool that has no feeling or emotions about about something that requires empathy makes me uneasy.","Personal & Emotional Life"
"5882","Religious decisions. AI does not seem to understand. But, other than that, I am generally in favour of AI other than for nefarious purposes such as to defraud me, encourage people to vote in ways that limit or impoverish them, deep-fakes, misinformation. All these require decisions. 


","Personal & Emotional Life"
"5883","For example diet. Imagine the AI decides what you eat and when you eat your food. This seems like a good thing because it will probably be good for your health. But you lose agency over your life and you also lose responsibility over your own life. Your mistakes will no longer be your own mistakes. If you get fat you will blame the AI instead of taking responsibility.  ","Personal & Emotional Life"
"5884","giving advice on any of my relationship ","Personal & Emotional Life"
"5885","I would feel uncomfortable with AI making decisions about medical treatment for a loved one. The specifics that make me uneasy include:

Lack of Empathy: AI cannot fully grasp emotional and psychological aspects of care that a human doctor would consider.
Complexity of Context: Medical decisions often require nuanced understanding of personal history and preferences that AI might not fully integrate.
Accountability: If an AI makes a poor decision, determining responsibility and recourse.","Medical & Healthcare"
"5886","Life choices ","Personal & Emotional Life"
"5887","Medical care. A human is best for this job. You cannot certainly depend on a robot to perform on your body. A human can understand emotions but not an AI. It is highly risky. You can research and improve health care using AI, however making AI (robots) to do the physical task, especially in the medical field is risky. ","Medical & Healthcare"
"5888","What I eat and what I wear, in fact, I pay great attention to my own subjective initiative. I think any decision I make is meaningful, even if it may not be the most fashionable, the healthiest, the most environmentally friendly, etc. decision in a professional sense.","Personal & Emotional Life"
"5889","I would feel uncomfortable with AI making decisions about my personal life, eating habits, and scheduling. I believe that AI lacks human experience and insight, which makes its work comparatively insignificant.","Personal & Emotional Life"
"5890","For example, when I arrive at a food city, I don’t need to ask AI which one is better, because AI’s answer does not have “personal” experience. Its results come from the Internet. If I ask it to help me make a decision, I will choose not to ask.","Personal & Emotional Life"
"5891","Decision related to financial budget and my savings, because they are based on certain rules and regulations whereas,human mind works on emotions and anxiety too. This will make sure for me to consider,the possible outcome,and select the best financial plan as per my requirement. Understanding my requirement is a key here .","Financial Decisions"
"5892","Big decisions, like family finances, or broader politics.","Financial Decisions"
"5893","The important decisions in life, which could impact my life profoundly. ","Personal & Emotional Life"
"5894","Scenario: When AI is involved as a car in an unavoidable accident where it must choose between the left side to safe a girl or right side to safe a child. Here uncomfortable aspects are lack of human empathy, potential bias, unclear decision making process etc.,","Life-or-Death & Moral Dilemmas"
"5895","Probably a decision in a courtroom. I can't really explain why but I feel like that would never truely work.","Legal & Justice System"
"5896","Micromanaging every detail of my life without providing an explanation or waiting for my approval","Loss of Human Agency & Control"
"5897","A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human is in the context of end-of-life care for a loved one. Imagine a situation where an AI system is used to determine the appropriate course of action for a critically ill patient, such as whether to continue aggressive treatment or to shift to palliative care.

","Life-or-Death & Moral Dilemmas"
"5898","Anything related to health","Medical & Healthcare"
"5899","Emotional topics or advice, or international politics","Personal & Emotional Life"
"5900","As preference changes according to time, culture, ethnicity and personality. I think AI might not consider these factors. Like for ex- while doing shopping AI will give me options to choose from based on my previous choices and experiences, however people change, time change and so do I ","Personal & Emotional Life"
"5901","Judging someone's life sentence in a trial.","Legal & Justice System"
"5902","relationship issues. i would not want Ai deciding that for me.","Personal & Emotional Life"
"5903","I’d be uncomfortable with AI deciding on a treatment for a serious illness. Health decisions need to consider personal values and emotions, which AI might miss. It feels too impersonal for something so important.","Medical & Healthcare"
"5904","Getting a medical diagnosis. I feel a human need is in this area and needs emotional understanding as well","Medical & Healthcare"
"5905","I would say social interactions, family life, raising kids","Personal & Emotional Life"
"5906","Maybe decisions related to health ","Medical & Healthcare"
"5907","When a detailed study has to be done on predefined things.","Uncategorized"
"5908","Big decisions","Personal & Emotional Life"
"5909","Keputusan final perusahaan seperti anggaran, keuangan, dll","Financial Decisions"
"5910","If an AI were built to make decisions in court, it would be uncomfortable.","Legal & Justice System"
"5912","Since I am a teacher, I would not like AI deciding how to teach. I believe every student is unique. So, human intervention is required to keep them grounded and understand the nuances of human psychology. AI in education might be good for resource development. But, if it substitutes a teacher, the outcome may be dangerous, as students will become more robotic than they are at present. ","Personal & Emotional Life"
"5913","Having an AI decide the death of a human would make me uncomfortable.","Life-or-Death & Moral Dilemmas"
"5914","War drones as civilians could be targeted and it may lack the element of discrimination when it comes to elimination of targets.Banks and other financial institutions,as an analysis tool is okay but it could be susceptible to hacking if contains information about people’s accounts.","Life-or-Death & Moral Dilemmas"
"5915","I would feel uncomfortable with an AI making a decision instead of a human regarding sensitive personal or financial information.","Data Privacy & Security"
"5916","deciding on which meeting to attend,who to call","Personal & Emotional Life"
"5917","I would not agree AI to be used as a decision-making tool in criminal justice due to it being bias . I would also not support AI use in the health sector, especially in delivering information as it lacks empathy.","Legal & Justice System"
"5918","A scenario where AI might make me uncomfortable is if it starts making highly personalized recommendations that feel intrusive, like predicting my emotions based on my conversations or monitoring my habits too closely, creating a sense of being constantly watched or manipulated.","Data Privacy & Security"
"5919","Legal cases or cases where human emotion might benefit the justice experienced by society. Sometime in the law i believe emotion and compassion should play a role in the way we deal with criminals.","Legal & Justice System"
"5920","Personal life decisions for relationships and friendships","Personal & Emotional Life"
"5921","Decide on my career goals, etc.","Hiring & Employment Decisions"
"5922","Important life decisions should be made by the individual. Artificial intelligence needs to provide factual information, but it should not have any bias or influence people's decisions.","Loss of Human Agency & Control"
"5923","diagnosing a disease based on the symptoms I have and suggesting medicines","Medical & Healthcare"
"5924","I feel uncomfortable if AI decides my medical plan without a senior/experience doctor's opinion.  ","Medical & Healthcare"
"5925","Apart from small, repetitive tasks that don’t require much thinking, I don’t like AI making decisions for me","Loss of Human Agency & Control"
"5926","in investment area like stock market, even developed a long time but it cannot replace final decision by human","Financial Decisions"
"5927","with investing decisions AI can provide market analysis and trends but I do not want to take its decisions on which stock to long or short.","Financial Decisions"
"5928","Any Final decision in a life changing decision. Humans might also be prone to error, when it comes to decisions, but in major desicions a human is needed to, at the very least, have someone to hold accontable","Loss of Human Agency & Control"
"5930","Health specific decisions","Medical & Healthcare"
"5931","The only thing I may feel unsafe about is giving up my personal information and being extensively brothered under surveillance through face recognition technology that tracks everything I do. I am very much worried about a surveillance state that may take away my right to freedom of rights and expression. I am also concerned about misleading information that AI social media could develop by state agents and bad criminal actors. ","Data Privacy & Security"
"5932","Purchasing descisions, of most things. I would like to decide based on information provided - given that information will likely be biased and influenced by AI, but at least I can feel like I am in control","Financial Decisions"
"5933","I feel uncomfortable with an  AI making a decision instead of a human in bank information because AI doesn't no the delicacy of personal data. Also if I need to share I will not do that because It happened with me once.","Financial Decisions"
"5934","I would feel uncomfortable with an AI making a decision instead of a human when it comes to a romantic relationship, they are not capable of making decisions based on emotions ","Personal & Emotional Life"
"5935","Choosing which career to take.

That the optimization algorithm is so advanced that despite ""giving me the right answer"" it ignores dreams and desires despite being far from ideal.","Hiring & Employment Decisions"
"5936","I would feel really uncomfortable for AI to undertake creative writings for me, for example: a story or diary","Creative & Artistic Pursuits"
"5937","Involving my core interests, financial issues, family issues, emotional issues and other major personal decisions","Personal & Emotional Life"
"5938","A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human might be in the context of a medical diagnosis or treatment plan for a serious condition. For example, imagine an AI being used to determine the course of treatment for a patient with cancer.","Medical & Healthcare"
"5939","A complex situation would be ordering food in a restaurant. Because you need another person's suggestion, because they have already tasted the food and not some robot or anything that would give you suggestion based on some statistics or marketing ideas.","Personal & Emotional Life"
"5940","Therapy/psychiatry evaluations and diagnosis","Medical & Healthcare"
"5941","For personal emotions","Personal & Emotional Life"
"5942","A concrete scenario where I would feel uncomfortable with an AI making a decision instead of a human is in medical diagnosis and treatment planning for a complex or life-threatening condition, such as cancer.Lack of Empathy and Human Intuition,Uncertainty in Edge Cases,Trust and Transparency.","Medical & Healthcare"
"5943","WHERE THE AI SUGGEST ME TO WHAT TO EAT AND WHAT TO WEAR. ","Personal & Emotional Life"
"5944","Ethical and Moral Judgments: Decisions involving complex ethical or moral considerations, such as those affecting human rights or welfare, can be too nuanced for AI to handle appropriately.

Emotional Support: Providing genuine emotional support, understanding, and empathy in personal or sensitive situations is something humans excel at, whereas AI may lack the depth of emotional insight required.","Life-or-Death & Moral Dilemmas"
"5945","I feel uncomfortable when AI make decission about how to spend my money and how AI making Decission about my Business.","Financial Decisions"
"5946","Driving a car and handling a medical surgery. This are things that depends on a lot of dependencies, which needs a human to make the decisions.","Medical & Healthcare"
"5947","When a political leader or head of state puts a branch of the military entirely under AI rule and allows it to decide whom to kill based on its broad orders.


So for example the government decides on mass surveillance and facial recognition by the AI to identify, isolate and eliminate its political targets as well as anyone they consider 'suspicious', autonomously.","Life-or-Death & Moral Dilemmas"
"5948","Criminal Cases","Legal & Justice System"
"5949","AI making decision on emotional topics like love and life wouldn't sit well with me. That should be entirely done by humans, as they have feelings and emotions.","Personal & Emotional Life"
"5950","On issues to do with emotions and feelings, I feel like AI should not be applicable. ","Personal & Emotional Life"
"5951","Most awkward scenario could be decision about one's personal life","Personal & Emotional Life"
"5952","I still can't say. I believe we are at a point where being careful with AI responses is a necessity. It is still progressing and makes many mistakes. We need to be careful.","General Mistrust / Inaccuracy"
"5953","AI determines employee promotions

Specific aspects that make me uncomfortable:

Lack of human considerations: AI may not be able to assess employees' soft skills and teamwork spirit.
Low transparency in decision-making: Employees cannot understand and question AI's decision-making process.
Data bias: AI may reflect bias in training data, leading to unfair promotions.
Lack of flexibility: AI may ignore employees' personal potential and future development.
Psychological impact on employees: Employees may feel that their efforts are ignored, affecting morale.","Hiring & Employment Decisions"
"5954","i think if they don't provide exact response as we want ","General Mistrust / Inaccuracy"
"5955","If AI is assigned to a specific task routine, as a human i lost my motivation to regain i wish to do some chores if AI can't be switched off or stopped from those activities it will be like make things not according to my wish, it should be in my control not out of my hands. I should be the decision make of use of AI","Loss of Human Agency & Control"
"5956","I don't want AI make a decision for my child.","Personal & Emotional Life"
"5957","when visiting a healthcare facility with a life threatening condition I would prefer the empathy of a human doctor to be making decisions.","Medical & Healthcare"
"5958","Medical purposes. If I were in a hospital, I would prefer that an actual doctor helps me instead of an AI. ","Medical & Healthcare"
"5959","a decision to pull the plug on a loved one","Life-or-Death & Moral Dilemmas"
"5960","Judging crimes. There is an aspect of empathy that needs to be taken into account.","Legal & Justice System"
"5961","An AI that would decide on a radical change in relationships with my loved ones or friends. I would take this as an abusive partner. And even if the decision is justified and reasoned, it would be perceived as intrusive in my private sphere.","Personal & Emotional Life"
"5962","A concrete example that makes me uncomfortable is the use of AI models to sort through CVs of people applying for positions in companies. In addition to not being ethical because there is no equal opportunity, the recruitment criteria are no longer ""human resources"" criteria.","Hiring & Employment Decisions"
"5963","medical and security decisions","Medical & Healthcare"
"5964","When he makes decisions about very private things like personal relationships.","Personal & Emotional Life"
"5965","a life changing operation that could be performed in two different way with two different outcomes.  I would not want an AI to decide that.  That is a personsal outcome and would also want the consultation of another human.","Medical & Healthcare"
"5966","Customer care- Some companies will leave all the customer needs to an AI and I think customers should be treated with affection.

Weapons- I think AI should not be trained in any way to be harmful to humans or to be used in wars.","Life-or-Death & Moral Dilemmas"
"5967","Maybe deciding what field to study or what to name your child or pet, haha. I feel like these things have to come from the heart","Personal & Emotional Life"
"5968","There is no understanding of desicion makig process, so I wouldn't deligate healthcare desicions","Medical & Healthcare"
"5969","How should i be living my life or day to day ","Personal & Emotional Life"
"5970","If AI made the decision of when I have to urinate or defecate.","Personal & Emotional Life"
"5971","If you decide that a person needs medical intervention or if a machine serves a client in person or on call","Medical & Healthcare"
"5972","For example, I would like to decide for myself which treatment options are the least likely to be tried for a cancer patient, if any, because in many cases, a contrary decision can be made based on physical findings alone.","Medical & Healthcare"
"5973","Companionship. Emotions. Family. Feeling. Togetherness. Friendship. Courtship. Caring for near and dear ones. 

All of the above are meant for humans since the time we have been civilised and none can take this away from us. If they do we being uneasy is not the correct word for it.","Personal & Emotional Life"
"5974","The main thing which scare me is regarding to security. People misuse the AI in many aspects also make AI generated photos and videos.","Data Privacy & Security"
"5975","Decisions pertaining to my employment. ","Hiring & Employment Decisions"
"5976","Medical resolutions that involve the health of a human being. It is a critical issue that can lead to death.","Medical & Healthcare"
"5977","If the AI decides to block or delete data on its own","Data Privacy & Security"
"5978","My most uncomfortable scenario on AI making a decision is on human drug prescription.","Medical & Healthcare"
"5979","Inconsistency with my understanding of the situation.","General Mistrust / Inaccuracy"
"5980","AI making the final decision in healthcare will make me uneasy. There are so many diseases and conditions with similar symptoms but vastly different root cause and treatment options. I don't think AI can diagnose each individual correctly and will give generic answers. It can provide cheap and accessible medical information and used for small health conditions but can't replace human medical experts. ","Medical & Healthcare"
"5981","Concerning my preferences on snacks and also fun activities..I don't think AI can be beneficial in such scenarios as I would want to be the one making this decisions by myself ","Personal & Emotional Life"
"5982","In healthcare, if there is an health emergency at home, I wouldn't want AI to decide the course of treatment but a known and accomplished physician.","Medical & Healthcare"
"5983","I would be uneasy about A.I making family decisions for me, i would rather handle my kids","Personal & Emotional Life"
"5984","Ai can make decisions on investment traffic updates, waking up time, daily routine. In my opinion some things like a career decisions should be carried out by humans because they know what they want to be and what their dreams are.","Hiring & Employment Decisions"
"5985","Advice on interpersonal relationships, such as suggestions on how to interact with others, whether to continue interacting with someone, etc.","Personal & Emotional Life"
"5986","For example, writing makes me feel that the word knowledge can no longer be enjoyed by humans alone.","Creative & Artistic Pursuits"
"5987","delicate and personal matters such as therapy, medical advice, and just overall medical and psychological issues.","Medical & Healthcare"
"5988","Interactions with other humans. Because it is a complicated process that needs a lot of context that was built over years.","Personal & Emotional Life"
"5989","As a human AI changes faces which will increase crimes","Data Privacy & Security"
"5990","In taking most of the decisions about any need.","Loss of Human Agency & Control"
"5991","Deciding who is selected for a job","Hiring & Employment Decisions"
"5992","Anything that could involve physical harm if something in the AI screws up.  For instance I wouldn't trust a self driving car at the moment because I don't feel it is advanced enough at this stage.","Life-or-Death & Moral Dilemmas"
"5993","When it becomes too close to my personal choices, like belief

","Personal & Emotional Life"
"5994","I hate the idea of AI being able to make diagnosis for my illnesses. This entails giving up my privacy by having various layers of users having access my data unnecessarily.","Medical & Healthcare"
"5995","I would feel uncomfortable if AI took over most of my life. I want to be responsible for most of my life and use AI to improve choices and decisions that are important to me, but only when I want it to. I feel uncomfortable knowing that they are trying to use artificial intelligence to replace 100% of our lives.","Loss of Human Agency & Control"
"5996","Some things are really uncomfortable when it comes to someone's identity, especially if it's at work. The more sophisticated the AI ​​that is developed, the less the use of the job field because with the presence of AI, someone who uses technology will feel that this use is more economical and efficient. Talking about someone's income is likely to be threatened by technology.","Hiring & Employment Decisions"
"5997","In matters that involve. emotions like dating and other forms of relationships and religion. Because in most cases, very little or no logic is engaged or even required.

AI will be the end of FAITH","Personal & Emotional Life"
"5998","Important decisions regarding medical treatments that could be fatal.","Medical & Healthcare"
"5999","In couple or personal decisions.","Personal & Emotional Life"
"6000","One aspects  that makes me uneasy will be letting an A.I babysit or look after young children without a human being present.","Personal & Emotional Life"
"6001","When there are other lives on the line","Life-or-Death & Moral Dilemmas"
"6002","Maybe any mistakes will be happened.","General Mistrust / Inaccuracy"
"6003","Let AI decide my future (what major to choose, what job to choose, what partner to choose)","Personal & Emotional Life"
"6004","My personal life. I wouldn't be comfortable sharing details with AI and I am a human being and have emotions so a machine can't really make decisions in this aspect. ","Personal & Emotional Life"
"6005","I would feel uncomfortable with AI deciding whether to end a person's life support in a hospital. The reason I find this unsettling is that it’s a deeply personal decision that involves a lot of emotions and values. AI might look at data and statistics, but it wouldn't understand the feelings of the family or the patient's wishes. It could make a choice based only on numbers, ignoring the human side of the situation.","Life-or-Death & Moral Dilemmas"
"6006","The holy time I would feel uncomfortable with AI is in choosing a girl to date as the result of an algorithm","Personal & Emotional Life"
"6007","I would be uncomfortable with having direct contact with an AI machine in a healthcare setting, as I value human connection more in vulnerable situations. I think AI can be used in healthcare to help doctors but it shouldn't be made obvious to the patient.","Medical & Healthcare"
"6008","In the medical field like in a pharmacy or surgery room.","Medical & Healthcare"
"6009","in nursing old people because they would lack the emotion of empathy.","Medical & Healthcare"
"6010","I would be uncomfortable with an Ai making decision in my love life. Matching me with potential partners with some scores is a no no for me. I want to get to meet them, talk and spend time and learn more about them and then decide on my won.","Personal & Emotional Life"
"6011","I wouldn't be comfortable taking a medical subscription from an AI compared to a doctor.","Medical & Healthcare"
"6012","I feel uncomfortable when asking health-related questions and whenever I need some human feelings not matching feelings.","Medical & Healthcare"
"6013","If the decision involved spending or investing a large sum of money then I would have to be very careful, however I would assume in this scenario there would be more than one AI tool available to advise me therefore I would still feel some sense of control.","Financial Decisions"
"6014","Taking decision is still ok, but it shouldn't do everything by itself. Everything should be like giving suggestions.","Loss of Human Agency & Control"
"6015","It would be in a company where the decisions are required for any deal in a meeting","Financial Decisions"
"6016","I guess the justice system will be a tricky one to give AI full control in deciding who should be punished or not. It might not be based on very small specific human actions but mostly based on previous formal information or statistic","Legal & Justice System"
"6017","As a marketing manager, I'd feel uncomfortable if AI decided on sensitive customer interactions, like handling complaints or personal issues. For example, if an AI automated response system mishandled a serious customer complaint, it might lack the empathy and nuance a human would provide. The impersonal nature of AI could escalate the issue, affecting customer satisfaction and brand reputation. I’m uneasy about the potential for AI to misinterpret emotional context and damaging relationships.","Personal & Emotional Life"
"6018","A concrete scenario where I would feel uncomfortable having decisions made by AI is a treatment decision in an emergency medical situation. For example, if I or a loved one were to face a serious illness, deciding which treatment method to use—relying solely on AI—might feel uncomfortable.","Medical & Healthcare"
"6019","Spying on an individuals devices without permission ","Data Privacy & Security"
"6020","Contacting other humans, predicting what responses could sound like me","Personal & Emotional Life"
"6021","To think that she could tell me what to do every minute, regardless of how I was feeling, somehow force me to do what needed to be done. That would be a specific imagination.","Loss of Human Agency & Control"
"6022","When it comes to personal issue why should a human made scientific Item decide which way I should live my life ","Personal & Emotional Life"
"6023","Ai deciding what I should do for fun for example where I should go travel as I largely value my own opinion and experience at least in my free time","Personal & Emotional Life"
"6024","That an AI decides my career advancement, without knowing the rules it follows.

","Hiring & Employment Decisions"
"6025","Health issue. If I am in need of a surgery I would feel uncomfortable to depend on the AI's decision.","Medical & Healthcare"
"6027","any major life decisions","Personal & Emotional Life"
"6028","Like how to take care of my feelings and children.","Personal & Emotional Life"
"6029","Mainly in decisions involving human and civil rights. These decisions are very delicate.

Choosing relationships, because this is something innate to human beings.

Creating some art or culture, because even cavemen created art and culture, we should not abandon this.","Personal & Emotional Life"
"6031","I would feel uncomfortable with AI being used in the court of law","Legal & Justice System"
"6032","It makes me uncomfortable to be discarded in a job selection process by an AI that didn't even really know me and just because it was programmed with a certain profile it discarded me.","Hiring & Employment Decisions"
"6033","The human or social aspect.","Personal & Emotional Life"
"6034","For example, choosing a university major. I believe that artificial intelligence cannot choose my major even if I give it all the specific information, and I will still be uncomfortable with the artificial intelligence’s decision.","Personal & Emotional Life"
"6035","Somehow, when using AI we have to explain in a very details explanation so that it can make it the way we want. Besides, we know what we want, we are just too lazy to create it by ourselves.","Loss of Human Agency & Control"
"6036","My personal/emotional decisions.","Personal & Emotional Life"
"6037","prediction on a classification matter (such as whether this is a good thing or not a good thing) or a regressive matter (such as a prediction in how much I will earn), especially with a probability of less than 85% (accuracy in this case)","General Mistrust / Inaccuracy"
"6038","Emotions. I think artificial intelligence cannot perceive the subtleties of human nature, at least it cannot understand you better than you do yourself. If you don’t trust yourself and can’t make choices on your own, then it’s futile to let humans or artificial intelligence make decisions for you. Artificial intelligence is a chimera of many human thoughts. They represent others and make decisions for others, but they cannot represent the feelings of specific people.","Personal & Emotional Life"
"6039","Imagine an AI deciding on a loved one’s medical treatment. I’d feel uneasy because AI lacks empathy and emotional understanding crucial in healthcare. It might miss personal nuances or emotional factors that a human doctor would consider. Additionally, AI decisions can be hard to question or hold accountable if something goes wrong, unlike a human professional who can provide explanations and take responsibility.







","Medical & Healthcare"
"6040","Sleep and rest schedule","Personal & Emotional Life"
"6041","Lack of human empathy: AI, no matter how advanced, doesn’t have the emotional intelligence or empathy that a doctor might offer when explaining risks and benefits, which is crucial in such a personal, high-stakes decision.
Over-reliance on data: AI would base its decision solely on data and statistics, but medical cases often have nuances that only a human doctor, with years of experience and intuition, might fully understand.
Accountability: In case the AI makes a wrong decision, it’s unclear ","Medical & Healthcare"
"6042","i wouldn't want AI deal with my medicines or my daily routines. Because sometimes we do things randomly and that's the fun of it."" randomness""","Personal & Emotional Life"
"6043","The concrete scenario can be while recruiting people for a given position. AI will help with the logic alone and not emotions which is an integral part of hiring process.","Hiring & Employment Decisions"
"6044","I would feel uncomfortable with AI making decisions about medical procedures I should go through. What makes this uncomfortable is that the AI model probably doesn't understand pain and I can't trust that it will understand mine","Medical & Healthcare"
"6045","About love and relationship","Personal & Emotional Life"
"6046","When AI decides the kind of medicine I take. ","Medical & Healthcare"
"6047","like to take my admission or not. Or pick a university. I can not even decied this. And people will always regret that what human being would do. I do not think when we regret the AI could take responsibilities.","Personal & Emotional Life"
"6048","""Work"" build character, without working we are becoming entitled and lazy. And unable to think creatively and having had the thought of ""oh well, good thing I dont have to work because So and So will do it for me"". ","Hiring & Employment Decisions"
"6049","A moral decision ","Life-or-Death & Moral Dilemmas"
"6050","My health or making an opinion about illness i am experiencing

","Medical & Healthcare"
"6051","I am uncomfortable with their participation in everyday tasks. I do not agree with a machine wanting to clean my house or tidy my clothes.","Personal & Emotional Life"
"6052","what specifically concerns me is the lack of empathy and nuanced understanding that a human doctor provides. An ai might make decisions based purely on data and probabilities, overlooking the individual’s preferences or the psychological and emotional aspcts of care. The idea of a machine making such deeply personal decisions feels unsettling because it reduces the human element in situations where compassion and human judgment are crucial.







","Medical & Healthcare"
"6053","When it comes to financial issues, i would rather explore more regarding to money issue and make my own decision.  i would take in consideration what AI suggest or offer with its reasons though.","Financial Decisions"
"6054","Anything to do with my life or choices. If I want to let AI write a meal plan for me, I can go do that. But I dont want AI making any decisions for me. It can suggest things to me","Loss of Human Agency & Control"
"6055","To plan my child's future as far as their education.  ","Personal & Emotional Life"
"6056","Taking on a job from which a human was earning a living.","Hiring & Employment Decisions"
"6057","it makes no sense asking AI about personal relationships coz the thing is that you can not explain your feelings to AI, so its pointless","Personal & Emotional Life"
"6058","In the workplace, they choose a person","Hiring & Employment Decisions"
"6059","Rearing children","Personal & Emotional Life"
"6060","In a way, I would not feel right with either an AI system to decide on the course of action to undertake with a terminal patient. AI seems not to be equipped to give the patient an embrace, appreciate patient’s value system and what the patient fears which are essential in such life-altering choices. Another disadvantage of a board of directors is that its decision making might also be questionable and therefore may cause some challenges of trust. ","Life-or-Death & Moral Dilemmas"
"6061","I would be feel uneasy if it interept in ny personal life.","Personal & Emotional Life"
"6062","Going through private photos and private data for a quick search.","Data Privacy & Security"
"6063","In my relationship life. Like dating websites, I don't feel comfortable with dating algorithms to match me with a potential lover. Things like this are sacred to me, and I would prefer finding my partner in the old-fashioned way. In the mall, parks or open events that my eyes could communicate with from the start. ","Personal & Emotional Life"
"6064","when planning a health treatment, because for me there are very important aspects that depend on attention, listening with emotion and considering aspects that involve the patient's freedom of choice.","Medical & Healthcare"
"6065","Fully deciding on my finances, or diet, or even social encounters. I think letting everything be controlled and decided by a machine can go very wrong long term. ","Financial Decisions"
"6066","I would feel uncomfortable if AI is deciding on what should I pursue or do with my life. I understand that AI will help in eradicating a lot of errors but that'll lead to a life too perfect. Perfection is doomed. I'll like to make mistakes along the road of my career and family.","Personal & Emotional Life"
"6067","in cases relating to health issues, I can never trust a non-breathing to have the same health pain as a human or any other living thing.","Medical & Healthcare"
"6068","I would feel uncomfortable with using AI to make a decision about an interpersonal relationship, because it does not have a human touch nor can it truly understand what it means to be a human.","Personal & Emotional Life"
"6069","At work and even at other industries, We cannot completely depend on AI to make right decisions. ","Hiring & Employment Decisions"
"6070","I wouldnt want AI to make decisions about my healthcare without my input. I would prefer it to lay out the options for me to decide on my own.","Medical & Healthcare"
"6071","Money and banking ","Financial Decisions"
"6072","I would feel uncomfortable if AI were to make personal health decisions, such as treatment options, without human input. The lack of empathy and nuanced understanding in AI decision-making, combined with potential biases in data, makes me uneasy about entrusting such sensitive and individualized choices solely to algorithms.","Medical & Healthcare"
"6073","I would feel uncomfortable for AI to make a decision in a life or death situation like in the hospital with highly sensitive cases that involve near death patients or organ donors.","Life-or-Death & Moral Dilemmas"
"6074","Making financial decisions in a company","Financial Decisions"
"6075","For example, when choosing a nutritious meal, AI requires me to eat the food I don’t like, but cannot give me other foods I like!","Personal & Emotional Life"
"6076","I am only going to be worried about it's thinking capacity exceeding that of humans and decides to amends or upskill itself more than human because of a possible poor programming","General Mistrust / Inaccuracy"
"6077","I would feel uneasy if an AI were responsible for making decisions involving deeply personal or emotional aspects of human life, such as handling a sensitive customer complaint related to a family issue. The human touch is essential for understanding the nuances of emotions and providing empathetic support. AI may lack the subtlety and warmth required to address these situations effectively, which could result in misunderstandings or a lack of genuine connection.","Personal & Emotional Life"
"6078","Making purchases and subscriptions on my behalf.","Financial Decisions"
"6079","Making a decision about Google Map destination.","Uncategorized"
"6080","conditions that make me uncomfortable when decisions are made by AI, namely regarding something that is personally related to my life, especially about my family.","Personal & Emotional Life"
"6081","Perhaps without us realizing it will gradually take away our human rights. ","Loss of Human Agency & Control"
"6082","The fact that many people have started having conversations with AI rather than an actual human being who can provide them with much-needed emotional support makes me uneasy. ","Personal & Emotional Life"
"6083","We humans are built differently in that we are biological beings and we do have a physical being and emotional part. We have intuition and rather a moral compass that influences our decisions. To be honest I won't be comfortable with an AI making decisions on the choosing of a political candidate, religion, Spouse, Employment and court cases verdict. Unlike AI we are unpredictable as we have a free will that guides ours decisions AI however gauges algorithms which could be misguided here.","Personal & Emotional Life"
"6084","Whenever I use social software, I hope to see new things, such as areas I have learned about, or aspects that I don’t usually pay attention to. However, every time I use social software, I am recommended things that I am interested in, or things similar to what I have clicked on before. This means that I can only restrict myself to the aspects that interest me, and cannot explore and understand other information. It is very unfree.","Loss of Human Agency & Control"
"6085","Any decision would involve consideration of humanity or human emotions I wouldn’t feel comfortable to be done by AI. ","Personal & Emotional Life"
"6086","Relationships and career","Personal & Emotional Life"
"6087","The first things that comes to mind is self-driving cars within the context of the classic “pulling the switch dilemma”. You know, would you pull the switch if there is one person standing on the tracks on one side and two people are standing on the other side. As these dilemmas get increasingly complicated, most people start displaying various biases. I imagine an AI would display even greater biases, as it learns the worst from imperfect humans","Life-or-Death & Moral Dilemmas"
"6088","Artificial intelligence plans my career prospects. It doesn't understand my interests and hobbies at all and only recommends boring jobs","Hiring & Employment Decisions"
"6089","I don't trust fully AI while choosing a college for my son. I will personally visit the campus instead of solely depending on AI suggestions.","Personal & Emotional Life"
"6090","All aspects make me uneasy, because I see fundamental value in the process of decision-making in and of itself. I think it is all very beautiful, the positive, and the negative outcomes of our decisions, and they are all necessary. We learn through failure too, and discover new paths and aspects of life through ""bad"" decisions as much as through ""good"" decisions. I disagree fundamentally with the need to be productive or efficient. There are other things that are of value in life.","Loss of Human Agency & Control"
"6091","To save my life instead of another life because of certain factors. Because it might too logical to end my life and I would not have a choice.","Life-or-Death & Moral Dilemmas"
"6092","Let's say a company wants to hire employees...if AI is used there would be biasness ","Hiring & Employment Decisions"
"6093","I would feel uncomfortable with an AI making decisions about critical medical care, as it may not understand empathy, ethics, personal history, and may not provide the necessary transparency.

","Medical & Healthcare"
"6094","I don’t want influence of AI interfere in the personal life.","Personal & Emotional Life"
"6095","I would feel uncomfortable if AI planned my schedule and asked me to do specific things at specific times.","Loss of Human Agency & Control"
"6096","AI deciding who to get a loan.","Financial Decisions"
"6097","i think that it will make me uneasy when it will be in my personal emotional life and not only tasks. ","Personal & Emotional Life"
"6099","An easy one: who do you fire in case of a need to downsize for a company. Ima assuming AI will fire the least efficient person, so this where human judgment comes in.","Hiring & Employment Decisions"
"6100","That they should replace psychologists, since I don't believe that an AI can reach the level of a human in terms of feelings.","Medical & Healthcare"
"6101","I don't know, most of my thoughts about AI are positive

","Uncategorized"
"6103","Related to relationship.","Personal & Emotional Life"
"6104","That hasn't happened yet. Since AI doesn't have emotions, it can't give us better suggestions for the most important decisions in our lives compared to us and our family, who know us best.","Personal & Emotional Life"
"6105","I would definitily be uncomfortable with AI making decisions about my finances, and personal information since I am concerned about the privacy of such things.","Financial Decisions"
"6106","About my children","Personal & Emotional Life"
"6107","life or death situations","Life-or-Death & Moral Dilemmas"
"6108","Driving","Life-or-Death & Moral Dilemmas"
"6109","Financial decisions, money management and administration

","Financial Decisions"
"6110","Final word in deciding the course of medical treatment","Medical & Healthcare"
"6111","if an AI can try to help me on how to romance or have sex with my partner this would make me feel uncomfartable","Personal & Emotional Life"
"6112","I would feel uneasy in a scenario where AI is doing a tradeoff between cost of treatment/surgery and likelihood of living or dying. I think that AI would sometimes say that the percentage chance of living would not be worth it given the monetary cost.","Life-or-Death & Moral Dilemmas"
"6113","For example, if a robot is used to perform surgery on a patient, I would worry about system disruption.","Medical & Healthcare"
"6114","In a medical context, I'd rather have a doctor telling me something than a robot.","Medical & Healthcare"
"6115","I would definitely feel uncomfortable if the AI was telling me what exactly to do with my body, for example get a surgery because the AI told me ","Medical & Healthcare"
"6116","I would probably be uncomfortable when the AI suggests something out of the context. ","General Mistrust / Inaccuracy"
"6117","More or less the my primary concern regarding AI is often related who is handling the information that I give and how safe it is in thier hands. I feel uneasy about small number conglomerates having control over vast population.","Data Privacy & Security"
"6118","Autonomous weapons

","Life-or-Death & Moral Dilemmas"
"6119","Matters involving life and death. Like in Intensive care units i.e in performing critical operations on patients. The fact that AI can fail makes me uneasy. ","Life-or-Death & Moral Dilemmas"
"6120","In areas dealing with human health I would prefer human beings to AI","Medical & Healthcare"
"6121","love?","Personal & Emotional Life"
"6122","A situation like medical emergency or high-demand surgical operation decision for relatives","Medical & Healthcare"
"6123","In illness and health, maybe it gives decision to do surgery or giving up or something.","Medical & Healthcare"
"6124","I would not want AI making important decisions in my life.","Loss of Human Agency & Control"
"6125","Driving me","Life-or-Death & Moral Dilemmas"
"6126","any decision related to my personal life would make me uncomfortable if it was made by an AI. for example if an judges if i was guilty of a crime or not, it would definitely bother me.","Legal & Justice System"
"6127","If I am found to have a terminal illness, I’d want to make my own choices as to how to spend my remaining days. I don’t want quantity of life without quality.","Medical & Healthcare"
"6128","I would feel uncomfortable if AI were to determine who I should meet or who I should commit to. 

I am referring to a future in which AI is the one that assigns us our partner without us having any objections. I would accept that by analyzing my tastes it suggests people I can meet, but without imposing anything on us.","Personal & Emotional Life"
"6129","I would be uncomfortable with the fact that an AI could make a difficult and complicated decision instead of a human. This is thinking about the capabilities of current AIs. A future AI could perhaps be more intelligent but more dangerous at the same time.","General Mistrust / Inaccuracy"
"6130","Personal ones. It is impossible for AI to feel, it is something that it will never achieve even with all the data available, AI cannot feel the sun on its face, the hot water when showering, the taste of food. Nor will it ever understand what it feels like to hug or kiss. Any interference by AI in these personal matters would be considered invasive and horrible.

","Personal & Emotional Life"
"6131","Relationship advice. I will prefer seeking advice from a human instead","Personal & Emotional Life"
"6132","Let AI drive the car","Life-or-Death & Moral Dilemmas"
"6133","AI helping me to plan a travel, will make me really uncomfortable","Personal & Emotional Life"
"6134","Because it runs on already available data and sometimes it is biased, I can't imagine taking help for my own decisions from a machine with no feeling because at the end life is mine and decisions are mine, it will stick with me not with the machine ","Loss of Human Agency & Control"
"6135","Asking a girl on a date for example ","Personal & Emotional Life"
"6137","Comforting someone, art and etc","Personal & Emotional Life"
"6138","Let us imagine a situation that I join a company to work for my monthly salary. If this company ensures that all their employees
 wear uniforms designed by AI.  If I am forced to wear any color that I do not like.","Hiring & Employment Decisions"
"6139","The decisions which need human touch","Personal & Emotional Life"
"6140","Sharing personal issues like my sexual life with an AI. I don't feel comfortable with that.","Personal & Emotional Life"
"6141","Medical decisions","Medical & Healthcare"
"6142","where to go","Personal & Emotional Life"
"6143","I don't like the idea of a computer program deciding things. I think they're good for consultation and assistance, but the final decision should never be made by an AI. It just makes me feel useless.","Loss of Human Agency & Control"
"6144","I would feel uncomfortable when AI would decide to make a decision regarding the kind of medicine I should take when I am suffering from a given disease. The aspects that can make me uneasy are the prescriptions of a machine rather than a human being. ","Medical & Healthcare"
"6145","About what to do or not to","Loss of Human Agency & Control"
"6146","I would feel uncomfortable with AI making decision on my investments and stocks instead of a human.","Financial Decisions"
"6147","Mathematical. ","Uncategorized"
"6148","Decisions where the outcome could be detrimental to me and my wellbeing.","Life-or-Death & Moral Dilemmas"
"6149","Getting married to someone and taking AI’s opinion in that","Personal & Emotional Life"
"6150","Any type of decision that is not purely logical and numerical, especially if it involves consequences for third parties.","Life-or-Death & Moral Dilemmas"
"6151","Any scenario where the decision would impact people's lives and potentially harm them. For example, diagnosing a patient and providing them with a treatment plan. There are too many nuances with humans that need to be looked at deeply by actual humans, not computers making a strictly statistical decision.","Medical & Healthcare"
"6152","The fact that my decisions are now locked makes me very uneasy.","Loss of Human Agency & Control"
"6153","I think these areas make it so uneasy for an AI 1. Personal Choice Challenges, 2. Unexplainable Outcomes, 3. Legal and Ethical Ambiguities 4. Reduced Motivation.
","Loss of Human Agency & Control"
"6154","In terms of medical care and transportation, because it involves personal safety, I cannot entrust my personal safety to a bunch of codes and controllers.","Medical & Healthcare"
"6155","When I use AI for emotional support during the time of grief.","Personal & Emotional Life"
"6156","Deciding on a treatment plan for a medical condition. I would want a human who would consider all aspects including personal comfort.","Medical & Healthcare"
"6157","Any thing about my health. ","Medical & Healthcare"
"6158","Literally anything involving human interaction. AI is not human and cannot know the implications of being human.","Personal & Emotional Life"
"6159","In the medical sector by having ai decide what disease you have and recommending the treatment 

In government by making tough economic decisions 

In the military by manufacturing weapons 

In job sector by having ai decide during interviews ","Medical & Healthcare"
"6160","I would feel uncomfortable if AI made important decisions for me and without my knowledge. For example, investments. Or the decision to perform a surgical operation.","Financial Decisions"
"6161","May be a life decisions which ai may not be appropriate to approach such as my fashion style may be some times the suggestions may be to blod to make me uneasy.

","Personal & Emotional Life"
"6162","My future. I don't want ai deciding that. It's mine . I don't trust it. I don't think it understands so much to decide my life for me. ","Personal & Emotional Life"
"6163","shopping decision, in therapy, in the hospital","Medical & Healthcare"
"6164","death sentence","Legal & Justice System"
"6165","Maybe to schedule appointments, based around my preferred dates and times.","Personal & Emotional Life"
"6166","Any decision that would affect humans life whether it be medical, legal, or for combat","Life-or-Death & Moral Dilemmas"
"6167","Anything that can have harmful effect both physical or mental","Life-or-Death & Moral Dilemmas"
"6168","Investment decisions, if everyone gets the same advice (and follows it) nobody gets rich, it turns into a pyramid scheme. For one to win, another must lose

","Financial Decisions"
"6169","I would not want an AI to have my health information especially if the AI is actively connected to the internet and is transferring my data to its developers.","Data Privacy & Security"
"6170","AI investing my money for me, without me approving it.","Financial Decisions"
"6171","Probably facing a dilemma about whether to pursue a career change that aligns with mu passion but involves some risks.","Hiring & Employment Decisions"
"6172","Decisions about dating and romance can't be fully entrusted to an AI. Love and dating should be personal and not technical.","Personal & Emotional Life"
"6173","I would get uncomfortable when a decision related to a stream of profession to be taken up in life would be decided by AI. Based on the technological inputs by the aspirant, AI can suggest but not decide for an aspirant. Human liking and emotions can’t be overpowered by AI. In all, AI can suggest as per the available data of the aspirant but not give in its final decision.","Hiring & Employment Decisions"
"6174","Determining every aspect of my life because I will literally be a zombie in my own life. ","Loss of Human Agency & Control"
"6175","In diagnosing a life threatening disease and selecting a treatment for a patient.

I'm sure AI would be an excellent help and is making healthcare very advanced but the ultimate decision maker should be a human as it will be a matter of life and death","Medical & Healthcare"
"6176","If many people are trapped in a coal mine, only two people can be saved by sacrificing them. Artificial intelligence decides to sacrifice two people by minimizing the cost. This makes me uncomfortable because there is no humanity, only calculation.","Life-or-Death & Moral Dilemmas"
"6177","Finding a life partner for myself. I feel that it requires human bias, life experience and personal preference to make this decision for myself. A computer is too cold and uncaring to do this.","Personal & Emotional Life"
"6178","When someone is sharing everything with AI and asks for advice, this situation will make me feel uncomfortable.","Personal & Emotional Life"
"6180","like having a serious health decision or in investment kind to market where the consequence of things going bad will be totally out of the picture","Medical & Healthcare"
"6181","I was working in a project where robots are working and then that robot dramatically destroy the system due to battery failure. ","Hiring & Employment Decisions"
"6183","When deciding salary to be payed for work done then ai decides based on the quality of the final product not considering the amount of work done","Hiring & Employment Decisions"
"6184","Telling me things to do, simple as that.","Loss of Human Agency & Control"
"6185","I guess the same scenarios on which I would feel uncomfortable telling one problem of mine to an actual human.

Giving personal info that otherwise would make me embarassed, if any other person found out. Examples: telling AI about my vulnerabilities, personal thoughts, specific weaknesses, fears, etc.","Data Privacy & Security"
"6186","Financial decisions and any decision of consequence.","Financial Decisions"
"6187","Investment advice, travel plans.","Financial Decisions"
"6188","If I'm having an important business conversation, I wouldn't trust AI completely for the correct translation. That would cost me a lot if AI failed to perform","General Mistrust / Inaccuracy"
"6189","It's difficult to think of a concrete example. Maybe I feel it's better for the decisions to be reviewed by humans who are knowledgeable about the subject.","Loss of Human Agency & Control"
"6190","In a case of criminal activity for example a robbery where a person is wrongfully accused. These are dangerous areas for AI to get involved in. We still need a human element in our justice system to figure out nuanced human behaviour. ","Legal & Justice System"
"6191","If a author has AI to write a book for him, I would be incredibly disappointed. The creative aspect of humans shouldn't be tampered by AI. Authors may be tempted by AI to create ideas, but this tarnishes the whole experience of reading a creative work.","Creative & Artistic Pursuits"
"6192","If I have to have surgery i would want both my doctor and the AIs opinion","Medical & Healthcare"
"6193","Literature review, AI always give me some fake literature","General Mistrust / Inaccuracy"
"6194","I was buying a gift for my boyfriend","Personal & Emotional Life"
"6195","I would be uncomfortable with AI making decisions about What to eat","Personal & Emotional Life"
"6196","when choosing for job position","Hiring & Employment Decisions"
"6197","What would me uneasy if it took over dating life and partner compability. People are a lot more complex in real life that you can constitute with questions and quizes to represent their personality and see if there is a compability.

In my opinion the spark between two people, love and a long-term relationship can not be judge by AI, not matter how vast its data bank is.","Personal & Emotional Life"
"6198","I would feel uncomfortable with an AI making end-of-life care decisions because it may lack the empathy and ethical consideration necessary for such deeply personal choices.","Life-or-Death & Moral Dilemmas"
"6199","Fate of humanity ","Life-or-Death & Moral Dilemmas"
"6200","assist me at my work tasks telling me the weather","Uncategorized"
"6201","I think, I don't have any such scenarios","Uncategorized"
"6202","In creating human relationships. I find it uncomfortable that AI will have a hand on choosing who you spends your time with based on ""calculated compatibility"". Relationships should be natural and grow on their own.","Personal & Emotional Life"
"6203","I’d be uncomfortable with AI making deeply personal decisions in emotional situations like in decisions involving healthcare. If I were diagnosed with a serious illness, I’d want a human, someone with empathy to explain my options and help me make decisions about my treatment. AI could lack the human touch that’s crucial in understanding my fears. A specific aspect that would make me uneasy is the lack of empathy","Medical & Healthcare"
"6204","Doing a surgery without presence of doctor ","Medical & Healthcare"
"6205","a scenario to whom my kids will marry.

Totally decided by manually","Personal & Emotional Life"
"6206","It would feel uneasy if an AI decided what I would have for breakfast, lunch, dinner etc. I'd like to keep control over certain decisions.","Personal & Emotional Life"
"6207","Decide for me whether to meet my family today and my major personal life choices.","Personal & Emotional Life"
"6208","Delivering justice. AI is not ready yet.","Legal & Justice System"
"6209","Financial decisions would make me uncomfortable, or things I am passionate about, fashion, food related","Financial Decisions"
"6210","When it comes to mental health, it makes me uneasy","Medical & Healthcare"
"6211","whom to love and marry","Personal & Emotional Life"
"6212","My personal life","Personal & Emotional Life"
"6213","I think that for certain ethical and moral choices, an AI will never be able to replace humans, for example certain religious groups do not think like others and AI could propose irrational solutions.","Life-or-Death & Moral Dilemmas"
"6214","really i don't have any senario with ai when i feeled it uncomfortable ","Uncategorized"
"6215","I think AI in medicine could have a huge benefit for doctors and patients. However, just because I think AI could be a benefit, I do not like the idea of having AI completely control the entire sector. The progression of AI into society shouldn't be understood as the elimination of jobs in a field. The only way I could support AI is if it is introduced as an aid, not the only option. So in medicine, I would be extremely unconfortable with AI making a decision on my health instead of a doctor.","Medical & Healthcare"
"6216","The choice to remove life support","Life-or-Death & Moral Dilemmas"
"6217","I do not want AI to decide anything about my career. In terms of career and jobs, I prioritize the feeling of suitability and comfortability over efficiency or profitability. I do not want my AI to make me work as a rocket scientist when I am happy working at post office.","Hiring & Employment Decisions"
"6218","I fear that AI will become too intelligent, to the point where we can no longer control it and too dependant on it in almost everything. Life decisions, investment etc ","Loss of Human Agency & Control"
"6219","AI generated response system, even to socialize we uses AI and that's for me is too far. ","Personal & Emotional Life"
"6220","If AI overtake in jobs and maintain the better infrastructure, on the name of advanced life, then AI could be dangerous in several ways in the future to overtake humans. ","Hiring & Employment Decisions"
"6221","My choice on any issues would never allow it.","Loss of Human Agency & Control"
"6222","Planning my time with my family and kids. I'd feel like it's taking over my position  in the lives of my family members","Personal & Emotional Life"
"6223","Smart system at home, TV, lights, air conditioning, automatically turn on at any time","Loss of Human Agency & Control"
"6224","Anything regarding my personal life that's family and work","Personal & Emotional Life"
"6226","I would be very uncomfortable if AI is used to fully operate airplanes and drones, especially in the military. I would not trust the AI to be rational as it might mistake innocent civilians to be enemies and cause a lot of collateral damage. A human would take time to assess the situation in a way AI would not.","Life-or-Death & Moral Dilemmas"
"6227","I would feel unfomfortable using AI into making highly human tasks, such as creative works, from wrting to art to  human interations. AI is very efficient in hendle high quantitiy of data, but humans must need to interact with eachothers and develop in a stymulating world for their mind, or we might come to a heavy social crisis.","Creative & Artistic Pursuits"
"6228","-In the field of health and politics. For me, AI has advantages and should be considered in some areas but not all areas.","Medical & Healthcare"
"6229","Help me eat, help me wipe my butt,","Personal & Emotional Life"
"6230","Hmm, a tough question. I think the specific aspects that will make me uneasy is they will be controlling our way of living in general and the decision slowly the higher management (ie. government, big companies) will tend to use AI as decision makers and we will lose the creativity and flexibility in problem solving.","Loss of Human Agency & Control"
"6231","Art, and anything creative related. I mean, as a tool yes, but I would rather not have it the sole foundation of it... Artists would be then treated as a commodity... I would much rather have Ai to partake in logical/practical tasks rather than creative ones!","Creative & Artistic Pursuits"
"6232","About my sex life","Personal & Emotional Life"
"6233","In healthcare, treating patients with terminally ill patients. Also for relationship advice and anything that involves empathy

","Medical & Healthcare"
"6234","Banking, security related matters","Financial Decisions"
"6235","when they assign 2 choices for me and I get to choose from the 2 choices. This is basically a mirage of me having a choice where i get to choose but ultimately it would be the AI choice

","Loss of Human Agency & Control"
"6236","all the decisions can not be taken by AI. Some decisions is taken very fast and seeing all the corn and porn ","General Mistrust / Inaccuracy"
"6237","Anything really. Particularly, creative, relationship-oriented decisions. Humans and our way of thinking are dynamic and responsive to the various colors of a situation. We also have our unique experience and intuition to guide us. This is something AI cannot replicate. ","Creative & Artistic Pursuits"
"6238","Ai is run through intenet. It always listen you and capture your style and records all information which you told to them. I fell uncomfortable for it. ","Data Privacy & Security"
"6239","Cyber insecurity makes me uneasy about AI","Data Privacy & Security"
"6240","I never allow AI the control over my money and spending","Financial Decisions"
"6241","Ending the relationship","Personal & Emotional Life"
"6242","Personal life.","Personal & Emotional Life"
"6243","Lack of transparency","General Mistrust / Inaccuracy"
"6244","Budgeting: I might allow AI to track my spending habits and suggest budget adjustments to improve savings or manage debt.","Financial Decisions"
"6246","Last time I asked Google's AI tool to help me plan a trip to Switzerland, including hotels and air tickets, but because their database was inaccurate and claimed to be real-time information but was not at all, the experience was very bad and I wasted a lot of time. In the end, I had to search and organize it myself again.","General Mistrust / Inaccuracy"
"6247","AI helps me develop a medical treatment that is contrary to the treatment plan offered by my doctor. I would feel uneasy as I am not sure what I can expect from AI's plan. I will play it safe and follow my doctor's recommendation.","Medical & Healthcare"
"6248","If a criminal suspect is tried in court and the entire trial process is completely controlled by an artificial intelligence system, I would feel uncomfortable. The core issue that makes me uncomfortable is that although artificial intelligence has significant advantages in data analysis and efficiency, it lacks human emotional understanding, moral judgment and respect for individuals. Especially in major decisions involving human freedom, rights and life, relying on artificial intelligence and excluding human participation makes me feel too cold and mechanical. This is not only a technical issue, but also an ethical and human issue.","Legal & Justice System"
"6249","Banking or serious medical conditions. ","Financial Decisions"
"6250","For example, in love, you choose the partner you like.","Personal & Emotional Life"
"6251","Right now, I would not trust AI with driving cars, flying planes, steering ships and other transportation since I don't believe it is advanced and safe enough to do so.","Life-or-Death & Moral Dilemmas"
"6252","I don't want artificial intelligence to make plans for me","Loss of Human Agency & Control"
"6253","I would be uncomfortable if AI decided which job offer I took","Hiring & Employment Decisions"
"6254","I would be horrified if the nuclear program of states was controlled by AI, although the fact that it is in the hands of people also horrifies me","Life-or-Death & Moral Dilemmas"
"6255","I cant really think of anything","Uncategorized"
"6256","In my opinion it’s when it a life or death situation ","Life-or-Death & Moral Dilemmas"
"6257","How to manage my finances and investments.","Financial Decisions"
"6258","Requesting a fatwa on a religious issue, because this smart system may be supported by parties hostile to my religion, and therefore incorrect information will be given.","Personal & Emotional Life"
"6259","I would be reluctant to eat food prepared by an AI robot when I wasn't looking. ","Personal & Emotional Life"
"6260","Chinese Chinese","Uncategorized"
"6261","Matters concerning health and other medical decisions.

Maybe if surgery is necessary or not or otherwise medical related decisions ","Medical & Healthcare"
"6262","I do not want AI making any personal or career changing decisions for me. ","Hiring & Employment Decisions"
"6263","Maybe in a therapy. ","Medical & Healthcare"
"6265","I'm not sure, to be clear.","Uncategorized"
"6266","In health I cannot imagine lying in theatre and a robot performs surgery on me .what if its battery dies or power goes off","Medical & Healthcare"
"6267","Like hotel robots. I would prefer a human rather than AI.","Hiring & Employment Decisions"
"6268","During warfare like the war in Russia AI could decide to annihilate while humans are still deciding on a truce.","Life-or-Death & Moral Dilemmas"
"6269","decide how to allocate donation money.","Financial Decisions"
"6270","Being uncomfortable, doing hard things that you end up not enjoying, being afraid and taking risks—these are the ways that we learn who we are and who we are not.When we take the risks away, we take away the learning opportunities.

When we remove the work for difficult answers, we only address easy questions.","Loss of Human Agency & Control"
"6271","Selecting life partner","Personal & Emotional Life"
"6272","Travel plan. I like a more free way","Personal & Emotional Life"
"6273","If artificial intelligence were to decide people's ideals and what they want to do in the future, I would feel uncomfortable.","Personal & Emotional Life"
"6274","Making an important company decision -- since the decision is complex, critical, and would involve multiple aspects.","Financial Decisions"
"6275","Maybe when I am in a hospital and in need of critical surgery. There are chances that the AI might know better than a doctor, but in the end, I will have more faith in a human than in a machine. ","Medical & Healthcare"
"6276","About the freedom of choice, it will be scary for AI to mandate an option for you, i always think of the movie Terminator and Skynet. Not far from becoming a reality if AI will be used in a wrong way.","Loss of Human Agency & Control"
"6277","Anything that is a matter of health or death. I wouldn't want to die because of a machine mistake.","Life-or-Death & Moral Dilemmas"
"6278","Driverless cars. After the news of a millionaire from America drowning in her Tesla and the car not allowing her to open the doors, this scenario became real.","Life-or-Death & Moral Dilemmas"
"6280","When I am bored, I will like it to stay that way But AI nowadays has ideas on how to kill boredom","Loss of Human Agency & Control"
"6281","I would be very uncomfortable if AI were to decide the grades for students’ Chinese assignments, art assignments, or classroom performance.","Creative & Artistic Pursuits"
"6282","Sexual activities such as ovulation ","Personal & Emotional Life"
"6283","that would be if AI power robot deploy to kill terrorist but find a child holding a knife or gun it will detect this as threat and shoot him","Life-or-Death & Moral Dilemmas"
"6284","Choosing what to invest my money in. This makes me uneasy because I wouldn't completely trust the AI.","Financial Decisions"
"6285","Unexpected","Uncategorized"
"6286","i think when I am going to sell my stocks. Trend is still going up but AI suggest to sell at this point.","Financial Decisions"
"6287","Ai human ","Uncategorized"
"6289","On the operating table, if the surgical plan is handed over to AI, or even AI performs the surgery, I would be particularly worried","Medical & Healthcare"
"6290","Unexpected","Uncategorized"
"6291","anything that depends on my creativity has no point being done by ai, the reason to do it is to do it. for example research, art etc","Creative & Artistic Pursuits"
"6292","Trust. Like most people I do not trust it. There are too many criminals out there that will dedicate their time to hacking the AI just for chaos and bad things. ","General Mistrust / Inaccuracy"
"6293","All I can think about is wars. Where an AI decides to kill all parties involved to end it. That would make my blood boil.","Life-or-Death & Moral Dilemmas"
"6294","Empathy, moral reasoning, and consideration about life's complex ethical dilemmas are abilities currently hard for AI to grasp. Life-and-death issues, for instance, or those issues that require other mature judgment by cultural or social context, are often better when human input is involved. Decisions having personal value, preference, and subjective experience are absolutely human-centric. For example, career decisions, personal relationships, and lifestyle choices informed by aspirations and ","Life-or-Death & Moral Dilemmas"
"6295","Meet new people","Personal & Emotional Life"
"6296","マインドハッキングに不安を感じています。


例えば、2019年の「リクナビ事件」が日本で起こり就職活動のプラットフォーム「リクナビ」を運営するリクルートキャリアが、学生のウェブ閲覧履歴などからAIを用いて内定辞退率を予測し、これを企業に販売していた。国内企業から採用をもらっても外資系に逃げてしまうような学生がいるので、そういった学生がどんなウェブをみていたかをAIに学習させて内定辞退の可能性を予測するアルゴリズムを組んでいたことが分かり、内定辞退率を予測するためのプロファイリングは、学生を採用する企業には有用だが、応募する側の学生にとってはショッキングだっただろう。まさか自分のウェブ閲覧履歴が内定辞退率の予測に使われ、内定が取り消される可能性があったとは思わなかったからです。","Hiring & Employment Decisions"
"6297","Almost anything. For example, to use the most mundane example, I hate cleaning the house, but I don't know if it will clean properly or prioritise the important things. Can it really see the stains on the floor that I see? Does it know that sticky stains are more important to get rid of? Will it just literally swipe everything under the rug? I am not a control freak but I can always find a loophole where it could interpret something wrong and do it wrong","Loss of Human Agency & Control"
"6298","in love","Personal & Emotional Life"
"6299","Art! Artists, singer, music makers are working really hard to produce something, and AI does the same in seconds. that's not fair
","Creative & Artistic Pursuits"
"6300","I log on to my banking website and the AI suggests some investment choices. Months later I turned a small profit but fees eat up that and part of the principal. I AI developer makes a bonus and I net a loss as well as new investment ideas","Financial Decisions"
"6301","In situations that require skill and attention like operating heavy machines ,surgery and  such","Life-or-Death & Moral Dilemmas"
"6302","AI medically performing any surgeries on me, letting AI take over my job completely. ","Medical & Healthcare"
"6303","It would make me uneasy knowing it's not a real person behind the AI. ","General Mistrust / Inaccuracy"
"6304","finding love, investing my money.","Personal & Emotional Life"
"6305","So","Uncategorized"
"6306","I don't have any scenario like that, I think AI is always going to be better at long term outcomes than humans.","Uncategorized"
"6307","Sentencing of criminals. The lack of humanity will bother me.","Legal & Justice System"
"6308","In the medical field during a surgical operation where the AI is trusted fully to carry out the whole procedure ","Medical & Healthcare"
"6309","Who to date","Personal & Emotional Life"
"6310","To let it take charge on military and army","Life-or-Death & Moral Dilemmas"
"6311","Imagine a scenario where an AI system is responsible for making end-of-life care decisions for patients in a hospital. This AI analyzes medical data, patient history, and predictive models to determine the best course of action, such as whether to continue aggressive treatment or to transition to palliative care.","Life-or-Death & Moral Dilemmas"
"6312","AI helping humans find partners","Personal & Emotional Life"
"6313","When we give ai to make decisions like in politics,ai can rule to throw a missile to another country which will make it a very big war that wasn't started by humans, that's my biggest fear","Life-or-Death & Moral Dilemmas"
"6314","Autonomous air movement eg planes","Life-or-Death & Moral Dilemmas"
"6315","In setting up security keys for accessing my online accounts and bank accounts, I feel much uncomfortable. ","Data Privacy & Security"
"6316","AI is not properly trained presently, so relaying totally on AI could be dangerous. Particularly saying that coding my algo trading program. ","General Mistrust / Inaccuracy"
"6317","I want to watch a niche movie that is not so good but I am interested in, but the artificial intelligence recommends me to watch another one through comprehensive analysis of box office reviews, word-of-mouth, and uses the same analysis to indicate that the movie I chose is not worth watching. The uncomfortable point is that my emotions and will are not determined by data analysis.","Personal & Emotional Life"
"6318","All artistic and creative aspects in general make me uncomfortable, as do any political decisions.","Creative & Artistic Pursuits"
"6319","I would not trust AI's suggestion in the finance area because the same suggestions were probably given to thousands of people. So they are not thrustworthy anymore","Financial Decisions"
"6320","AI can eliminate jobs","Hiring & Employment Decisions"
"6321","basically, an AI doing surgery. this is because while it would be based on optimal success, accidents do happen, perhaps an issue with the source of power could decide whether I live or die.","Medical & Healthcare"
"6322","education, therapy, artistic topics","Personal & Emotional Life"
"6324","Any medical scenario probably ","Medical & Healthcare"
"6325","I would feel uneasy if AI surveillance is used. Especially at work. Also AI completely taking over crucial tasks like rocket launches or heart surgeries ","Data Privacy & Security"
"6326","I would feel uncomfortable if AI decided who should receive medical treatment during a shortage because it might not consider the human emotions and unique situations involved. It makes me uneasy to think a machine could decide who gets help and who doesn’t.","Medical & Healthcare"
"6327","Finding a life partner or even a friend","Personal & Emotional Life"
"6328","Deciding who should be my friend or who I should date","Personal & Emotional Life"
"6329","Financial decisions, since they could be influenced by third parties. Some new type of ""advertising""","Financial Decisions"
"6331","Investing in stocks on my behalf. What if I loose all my money?","Financial Decisions"
"6332","A decision that involves a life and death situation or a major investment. ","Life-or-Death & Moral Dilemmas"
"6333","choosing which games i should buy. steam's algorithm is pretty bad for that. it would be a waste of money","Financial Decisions"
"6334","I don't like AI","Uncategorized"
"6335","For a day's plan, I don't want my calculations to be configured according to a fixed algorithm every day.","Personal & Emotional Life"
"6336","并产生关于这些内容的虚假信息

","General Mistrust / Inaccuracy"
"6337","choosing who to date i guess :v","Personal & Emotional Life"
"6339","If we face to earth warm issue, AI could decide to Human is danguous someting, AI will make a plan of delete us. ","Life-or-Death & Moral Dilemmas"
"6340","Perfoming a surgery, most especially a major one like the heart of head.","Medical & Healthcare"
"6341","Weapons","Life-or-Death & Moral Dilemmas"
"6342","the non-human touch. Whether in medicine or in pedagogy, I prefer the human character","Personal & Emotional Life"
"6343","I work in the design industry, so when artificial intelligence can automatically generate some creative images and iterate, I feel that the creative industry has become empty. It is true that artificial intelligence can generate a lot of cool renderings, but I think the most important thing in the design field is the creativity and logic behind the renderings and their practical effects, and their impact on the group, society and culture, which is difficult for artificial intelligence to replace.","Creative & Artistic Pursuits"
"6344","For example, to invest all my money in some stocks. I am not a risk taker.  ","Financial Decisions"
"6345","I am in the supermarket and I decide to buy some steaks for the weekend. AI says that meat is killing the planet. Well, AI bot, I don't care what you think. Climate change is a massive scam. I'm buying more steaks now.","Personal & Emotional Life"
"6346","Selecting the courses that are good when wanting to join college ","Personal & Emotional Life"
"6347","没有","Uncategorized"
"6348","Taking Carr of my kids","Personal & Emotional Life"
"6349","I don't very much depends on AI.","Loss of Human Agency & Control"
"6350","When I want to indulge in some junk food, fried chicken, pizza, and cola, AI opposes me and arranges healthy food for me.","Personal & Emotional Life"
"6351","Can’t think of it for now

","Uncategorized"
"6352","If this picture is drawn by artificial intelligence, I will feel uncomfortable","Creative & Artistic Pursuits"
"6353","Art","Creative & Artistic Pursuits"
"6354","tidak keberatan","Uncategorized"
"6355","About where I would place my investment,","Financial Decisions"
"6356","AI cooking for me","Personal & Emotional Life"
"6357","Any major purchases that can be financially leveraged by the seller in a way that is not fair or mutually beneficial. For example, a car or property that is artificially marketed/advertised to exploit my personal desires because the seller decided to use the AI in a nefarious or manipulative way. ","Financial Decisions"
"6358","For a medical operation","Medical & Healthcare"
"6359","I would feel uncomfortable if AI were to have full acces my bank ","Financial Decisions"
"6360","","Uncategorized"
"6361","as of right now there none, since its helping me alot","Uncategorized"
"6362","Not available at the moment

","Uncategorized"
